{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Laboratorio 1 - Parte 1\n",
    "\n",
    "### Regresión polinomial múltiple\n",
    "\n",
    "### 2019 - II\n",
    "\n",
    "#### Profesor: Julián D. Arias Londoño\n",
    "#### julian.ariasl@udea.edu.co\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Guía del laboratorio\n",
    "\n",
    "En este archivo va a encontrar tanto celdas de código como celdas de texto con las instrucciones para desarrollar el laboratorio.\n",
    "\n",
    "Lea atentamente las instrucciones entregadas en las celdas de texto correspondientes y proceda con la solución de las preguntas planteadas.\n",
    "\n",
    "Nota: no olvide ir ejecutando las celdas de código de arriba hacia abajo para que no tenga errores de importación de librerías o por falta de definición de variables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Primer integrante:\n",
    "Nombre: Jorge Hiler Ricardo\n",
    "\n",
    "\n",
    "#### Segundo integrante:\n",
    "\n",
    "Nombre: Santiago Gaviria Zapata\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['LotFrontage', 'MasVnrType', 'MasVnrArea', 'BsmtQual', 'BsmtCond', 'BsmtExposure', 'BsmtFinType1', 'BsmtFinType2', 'Electrical', 'FireplaceQu', 'GarageType', 'GarageYrBlt', 'GarageFinish', 'GarageQual', 'GarageCond']\n",
      "['MSZoning', 'LotFrontage', 'MasVnrType', 'MasVnrArea', 'BsmtQual', 'BsmtCond', 'BsmtExposure', 'BsmtFinType1', 'BsmtFinSF1', 'BsmtFinType2', 'BsmtFinSF2', 'BsmtUnfSF', 'TotalBsmtSF', 'BsmtFullBath', 'BsmtHalfBath', 'FireplaceQu', 'GarageType', 'GarageYrBlt', 'GarageFinish', 'GarageCars', 'GarageArea', 'GarageQual', 'GarageCond']\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import numpy.matlib as npMatlib\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "#from scipy import stats\n",
    "\n",
    "#Algunas advertencias que queremos evitar\n",
    "import warnings\n",
    "warnings.filterwarnings(\"always\")\n",
    "\n",
    "train = pd.read_csv(r'DB/train.csv')\n",
    "\n",
    "test = pd.read_csv(r'DB/test.csv')\n",
    "\n",
    "naTrainResultantColumns = train.columns[train.isna().any()].tolist()\n",
    "naTestColumns = test.columns[test.isna().any()].tolist()\n",
    "print(naTrainResultantColumns)\n",
    "print(naTestColumns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio 1: Contextualización del problema\n",
    "\n",
    "El problema de *regresión* que abordaremos consiste en predecir el valor de la humedad absoluta en el aire, a partir de varias variables sensadas en el aire (Para más información sobre la base de datos y la contextualización del problema, consulte: http://archive.ics.uci.edu/ml/datasets/air+quality). Ejecute la siguiente celda para cargar los datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numero de columnas con valores NA:  0\n",
      "Numero de columnas con valores NA:  0\n",
      "Lllenado de campos vacíos completado\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "def fillNAs(train, test):\n",
    "    naTrainColumns = train.columns[train.isna().any()].tolist()\n",
    "    train[naTrainColumns[0]].fillna(train[naTrainColumns[0]].mean(), inplace = True)\n",
    "    train[naTrainColumns[1]].fillna('None', inplace = True)\n",
    "    train[naTrainColumns[2]].fillna(train[naTrainColumns[2]].mean(), inplace = True)\n",
    "    train[naTrainColumns[3]].fillna('NA', inplace = True)\n",
    "    train[naTrainColumns[4]].fillna('NA', inplace = True)\n",
    "    train[naTrainColumns[5]].fillna('NA', inplace = True)\n",
    "    train[naTrainColumns[6]].fillna('NA', inplace = True)\n",
    "    train[naTrainColumns[7]].fillna('NA', inplace = True)\n",
    "    train[naTrainColumns[8]].fillna('SBrkr', inplace = True)\n",
    "    train[naTrainColumns[9]].fillna('NA', inplace = True)\n",
    "    train[naTrainColumns[10]].fillna('NA', inplace = True)\n",
    "    train[naTrainColumns[11]].fillna(train[naTrainColumns[11]].mean(), inplace = True)\n",
    "    train[naTrainColumns[12]].fillna('NA', inplace = True)\n",
    "    train[naTrainColumns[13]].fillna('NA', inplace = True)\n",
    "    train[naTrainColumns[14]].fillna('NA', inplace = True)\n",
    "    \n",
    "    naTrainResultantColumns = train.columns[train.isna().any()].size\n",
    "    print('Numero de columnas con valores NA: ', naTrainResultantColumns)\n",
    "    \n",
    "    naTestColumns = test.columns[test.isna().any()].tolist()\n",
    "    \n",
    "    test[naTestColumns[0]].fillna('RL', inplace = True)\n",
    "    test[naTestColumns[1]].fillna(test[naTestColumns[1]].mean(), inplace = True)\n",
    "    test[naTestColumns[2]].fillna('None', inplace = True)\n",
    "    test[naTestColumns[3]].fillna(test[naTestColumns[3]].mean(), inplace = True)\n",
    "    test[naTestColumns[4]].fillna('NA', inplace = True)\n",
    "    test[naTestColumns[5]].fillna('NA', inplace = True)\n",
    "    test[naTestColumns[6]].fillna('NA', inplace = True)\n",
    "    test[naTestColumns[7]].fillna('NA', inplace = True)\n",
    "    test[naTestColumns[8]].fillna(test[naTestColumns[8]].mean(), inplace = True)\n",
    "    test[naTestColumns[9]].fillna('NA', inplace = True)\n",
    "    test[naTestColumns[10]].fillna(test[naTestColumns[10]].mean(), inplace = True)\n",
    "    test[naTestColumns[11]].fillna(test[naTestColumns[11]].mean(), inplace = True)\n",
    "    test[naTestColumns[12]].fillna(test[naTestColumns[12]].mean(), inplace = True)\n",
    "    test[naTestColumns[13]].fillna(test[naTestColumns[13]].mean(), inplace = True)\n",
    "    test[naTestColumns[14]].fillna(test[naTestColumns[14]].mean(), inplace = True)\n",
    "    test[naTestColumns[15]].fillna('NA', inplace = True)\n",
    "    test[naTestColumns[16]].fillna('NA', inplace = True)\n",
    "    test[naTestColumns[17]].fillna(test[naTestColumns[17]].mean(), inplace = True)\n",
    "    test[naTestColumns[18]].fillna('NA', inplace = True)\n",
    "    test[naTestColumns[19]].fillna(round(float(test[naTestColumns[19]].mean()), 1), inplace = True)\n",
    "    test[naTestColumns[20]].fillna(test[naTestColumns[20]].mean(), inplace = True)\n",
    "    test[naTestColumns[21]].fillna('NA', inplace = True)\n",
    "    test[naTestColumns[22]].fillna('NA', inplace = True)\n",
    "    \n",
    "    naTestResultantColumns = train.columns[train.isna().any()].size\n",
    "    print('Numero de columnas con valores NA: ', naTestResultantColumns)\n",
    "    \n",
    "    if (naTrainResultantColumns == 0 & naTestResultantColumns == 0):\n",
    "        return print(\"Lllenado de campos vacíos completado\")\n",
    "    else: \n",
    "        return print(\"Llenado de campos vacíos erróneo\")\n",
    "\n",
    "fillNAs(train, test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Responda:\n",
    "\n",
    "1.1 Cuántas muestras tiene la base de datos?: \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Deleted columns 'cause had a lot of NA > 80%: 'Alley','Fence','MiscFeature','PoolQC'\n",
    "#Deleted columns 'cause the std = 0: 'Utilities' %rep = 1, 'Street' %rep =1,\n",
    "#'LandSlope' %rep = 0.95, Condition2 %rep = 1445/1460, RoofMatl %rep = 1434/1460, \n",
    "# Heating %rep = 1428/1460, LowQualFinSF %rep = 1436/1460, \n",
    "# PoolArea %rep = 1454/1460, 3SsnPorch %rep = 1438/1460\n",
    "\n",
    "def deleteColumns(train, test):\n",
    "    columnsToDelete = ['Id','Utilities','Street','LandSlope', 'Condition2', 'RoofMatl',  'Heating', 'LowQualFinSF', 'PoolArea', '3SsnPorch']\n",
    "    train.drop(labels = columnsToDelete, axis = 1, inplace = True)\n",
    "    test.drop(labels = columnsToDelete, axis = 1, inplace = True)\n",
    "    \n",
    "deleteColumns(train, test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.2 Cuántas caracteristicas tiene el problema?: \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 2912 entries, 0 to 1451\n",
      "Data columns (total 204 columns):\n",
      " #   Column                 Dtype   \n",
      "---  ------                 -----   \n",
      " 0   LotFrontage            float64 \n",
      " 1   LotArea                int64   \n",
      " 2   OverallQual            int64   \n",
      " 3   OverallCond            int64   \n",
      " 4   YearBuilt              int64   \n",
      " 5   YearRemodAdd           int64   \n",
      " 6   MasVnrArea             float64 \n",
      " 7   ExterQual              int64   \n",
      " 8   ExterCond              int64   \n",
      " 9   BsmtQual               int64   \n",
      " 10  BsmtCond               int64   \n",
      " 11  BsmtExposure           int64   \n",
      " 12  BsmtFinSF1             float64 \n",
      " 13  BsmtFinSF2             float64 \n",
      " 14  BsmtUnfSF              float64 \n",
      " 15  TotalBsmtSF            float64 \n",
      " 16  HeatingQC              int64   \n",
      " 17  1stFlrSF               int64   \n",
      " 18  2ndFlrSF               int64   \n",
      " 19  GrLivArea              int64   \n",
      " 20  BsmtFullBath           float64 \n",
      " 21  BsmtHalfBath           float64 \n",
      " 22  FullBath               int64   \n",
      " 23  HalfBath               int64   \n",
      " 24  BedroomAbvGr           int64   \n",
      " 25  KitchenAbvGr           int64   \n",
      " 26  KitchenQual            int64   \n",
      " 27  TotRmsAbvGrd           int64   \n",
      " 28  Fireplaces             int64   \n",
      " 29  FireplaceQu            int64   \n",
      " 30  GarageYrBlt            float64 \n",
      " 31  GarageCars             float64 \n",
      " 32  GarageArea             float64 \n",
      " 33  GarageQual             int64   \n",
      " 34  GarageCond             int64   \n",
      " 35  WoodDeckSF             int64   \n",
      " 36  OpenPorchSF            int64   \n",
      " 37  EnclosedPorch          int64   \n",
      " 38  ScreenPorch            int64   \n",
      " 39  MiscVal                int64   \n",
      " 40  MoSold                 int64   \n",
      " 41  YrSold                 int64   \n",
      " 42  MSSubClass_30          uint8   \n",
      " 43  MSSubClass_40          uint8   \n",
      " 44  MSSubClass_45          uint8   \n",
      " 45  MSSubClass_50          uint8   \n",
      " 46  MSSubClass_60          uint8   \n",
      " 47  MSSubClass_70          uint8   \n",
      " 48  MSSubClass_75          uint8   \n",
      " 49  MSSubClass_80          uint8   \n",
      " 50  MSSubClass_85          uint8   \n",
      " 51  MSSubClass_90          uint8   \n",
      " 52  MSSubClass_120         uint8   \n",
      " 53  MSSubClass_150         uint8   \n",
      " 54  MSSubClass_160         uint8   \n",
      " 55  MSSubClass_180         uint8   \n",
      " 56  MSSubClass_190         uint8   \n",
      " 57  MSZoning_FV            uint8   \n",
      " 58  MSZoning_RH            uint8   \n",
      " 59  MSZoning_RL            uint8   \n",
      " 60  MSZoning_RM            uint8   \n",
      " 61  LotShape_IR2           uint8   \n",
      " 62  LotShape_IR3           uint8   \n",
      " 63  LotShape_Reg           uint8   \n",
      " 64  LandContour_HLS        uint8   \n",
      " 65  LandContour_Low        uint8   \n",
      " 66  LandContour_Lvl        uint8   \n",
      " 67  LotConfig_CulDSac      uint8   \n",
      " 68  LotConfig_FR2          uint8   \n",
      " 69  LotConfig_FR3          uint8   \n",
      " 70  LotConfig_Inside       uint8   \n",
      " 71  Neighborhood_Blueste   uint8   \n",
      " 72  Neighborhood_BrDale    uint8   \n",
      " 73  Neighborhood_BrkSide   uint8   \n",
      " 74  Neighborhood_ClearCr   uint8   \n",
      " 75  Neighborhood_CollgCr   uint8   \n",
      " 76  Neighborhood_Crawfor   uint8   \n",
      " 77  Neighborhood_Edwards   uint8   \n",
      " 78  Neighborhood_Gilbert   uint8   \n",
      " 79  Neighborhood_IDOTRR    uint8   \n",
      " 80  Neighborhood_MeadowV   uint8   \n",
      " 81  Neighborhood_Mitchel   uint8   \n",
      " 82  Neighborhood_NAmes     uint8   \n",
      " 83  Neighborhood_NPkVill   uint8   \n",
      " 84  Neighborhood_NWAmes    uint8   \n",
      " 85  Neighborhood_NoRidge   uint8   \n",
      " 86  Neighborhood_NridgHt   uint8   \n",
      " 87  Neighborhood_OldTown   uint8   \n",
      " 88  Neighborhood_SWISU     uint8   \n",
      " 89  Neighborhood_Sawyer    uint8   \n",
      " 90  Neighborhood_SawyerW   uint8   \n",
      " 91  Neighborhood_Somerst   uint8   \n",
      " 92  Neighborhood_StoneBr   uint8   \n",
      " 93  Neighborhood_Timber    uint8   \n",
      " 94  Neighborhood_Veenker   uint8   \n",
      " 95  Condition1_Feedr       uint8   \n",
      " 96  Condition1_Norm        uint8   \n",
      " 97  Condition1_PosA        uint8   \n",
      " 98  Condition1_PosN        uint8   \n",
      " 99  Condition1_RRAe        uint8   \n",
      " 100 Condition1_RRAn        uint8   \n",
      " 101 Condition1_RRNe        uint8   \n",
      " 102 Condition1_RRNn        uint8   \n",
      " 103 BldgType_2fmCon        uint8   \n",
      " 104 BldgType_Duplex        uint8   \n",
      " 105 BldgType_Twnhs         uint8   \n",
      " 106 BldgType_TwnhsE        uint8   \n",
      " 107 HouseStyle_1.5Unf      uint8   \n",
      " 108 HouseStyle_1Story      uint8   \n",
      " 109 HouseStyle_2.5Fin      uint8   \n",
      " 110 HouseStyle_2.5Unf      uint8   \n",
      " 111 HouseStyle_2Story      uint8   \n",
      " 112 HouseStyle_SFoyer      uint8   \n",
      " 113 HouseStyle_SLvl        uint8   \n",
      " 114 RoofStyle_Gable        uint8   \n",
      " 115 RoofStyle_Gambrel      uint8   \n",
      " 116 RoofStyle_Hip          uint8   \n",
      " 117 RoofStyle_Mansard      uint8   \n",
      " 118 RoofStyle_Shed         uint8   \n",
      " 119 Exterior1st_AsphShn    uint8   \n",
      " 120 Exterior1st_BrkComm    uint8   \n",
      " 121 Exterior1st_BrkFace    uint8   \n",
      " 122 Exterior1st_CBlock     uint8   \n",
      " 123 Exterior1st_CemntBd    uint8   \n",
      " 124 Exterior1st_HdBoard    uint8   \n",
      " 125 Exterior1st_ImStucc    uint8   \n",
      " 126 Exterior1st_MetalSd    uint8   \n",
      " 127 Exterior1st_Plywood    uint8   \n",
      " 128 Exterior1st_Stone      uint8   \n",
      " 129 Exterior1st_Stucco     uint8   \n",
      " 130 Exterior1st_VinylSd    uint8   \n",
      " 131 Exterior1st_Wd Sdng    uint8   \n",
      " 132 Exterior1st_WdShing    uint8   \n",
      " 133 Exterior2nd_AsphShn    uint8   \n",
      " 134 Exterior2nd_Brk Cmn    uint8   \n",
      " 135 Exterior2nd_BrkFace    uint8   \n",
      " 136 Exterior2nd_CBlock     uint8   \n",
      " 137 Exterior2nd_CmentBd    uint8   \n",
      " 138 Exterior2nd_HdBoard    uint8   \n",
      " 139 Exterior2nd_ImStucc    uint8   \n",
      " 140 Exterior2nd_MetalSd    uint8   \n",
      " 141 Exterior2nd_Other      uint8   \n",
      " 142 Exterior2nd_Plywood    uint8   \n",
      " 143 Exterior2nd_Stone      uint8   \n",
      " 144 Exterior2nd_Stucco     uint8   \n",
      " 145 Exterior2nd_VinylSd    uint8   \n",
      " 146 Exterior2nd_Wd Sdng    uint8   \n",
      " 147 Exterior2nd_Wd Shng    uint8   \n",
      " 148 MasVnrType_BrkFace     uint8   \n",
      " 149 MasVnrType_None        uint8   \n",
      " 150 MasVnrType_Stone       uint8   \n",
      " 151 Foundation_CBlock      uint8   \n",
      " 152 Foundation_PConc       uint8   \n",
      " 153 Foundation_Slab        uint8   \n",
      " 154 Foundation_Stone       uint8   \n",
      " 155 Foundation_Wood        uint8   \n",
      " 156 BsmtFinType1_BLQ       uint8   \n",
      " 157 BsmtFinType1_GLQ       uint8   \n",
      " 158 BsmtFinType1_LwQ       uint8   \n",
      " 159 BsmtFinType1_NA        uint8   \n",
      " 160 BsmtFinType1_Rec       uint8   \n",
      " 161 BsmtFinType1_Unf       uint8   \n",
      " 162 BsmtFinType2_BLQ       uint8   \n",
      " 163 BsmtFinType2_GLQ       uint8   \n",
      " 164 BsmtFinType2_LwQ       uint8   \n",
      " 165 BsmtFinType2_NA        uint8   \n",
      " 166 BsmtFinType2_Rec       uint8   \n",
      " 167 BsmtFinType2_Unf       uint8   \n",
      " 168 CentralAir_Y           uint8   \n",
      " 169 Electrical_FuseF       uint8   \n",
      " 170 Electrical_FuseP       uint8   \n",
      " 171 Electrical_Mix         uint8   \n",
      " 172 Electrical_SBrkr       uint8   \n",
      " 173 Functional_Maj2        uint8   \n",
      " 174 Functional_Min1        uint8   \n",
      " 175 Functional_Min2        uint8   \n",
      " 176 Functional_Mod         uint8   \n",
      " 177 Functional_Sev         uint8   \n",
      " 178 Functional_Typ         uint8   \n",
      " 179 GarageType_Attchd      uint8   \n",
      " 180 GarageType_Basment     uint8   \n",
      " 181 GarageType_BuiltIn     uint8   \n",
      " 182 GarageType_CarPort     uint8   \n",
      " 183 GarageType_Detchd      uint8   \n",
      " 184 GarageType_NA          uint8   \n",
      " 185 GarageFinish_NA        uint8   \n",
      " 186 GarageFinish_RFn       uint8   \n",
      " 187 GarageFinish_Unf       uint8   \n",
      " 188 PavedDrive_P           uint8   \n",
      " 189 PavedDrive_Y           uint8   \n",
      " 190 SaleType_CWD           uint8   \n",
      " 191 SaleType_Con           uint8   \n",
      " 192 SaleType_ConLD         uint8   \n",
      " 193 SaleType_ConLI         uint8   \n",
      " 194 SaleType_ConLw         uint8   \n",
      " 195 SaleType_New           uint8   \n",
      " 196 SaleType_Oth           uint8   \n",
      " 197 SaleType_WD            uint8   \n",
      " 198 SaleCondition_AdjLand  uint8   \n",
      " 199 SaleCondition_Alloca   uint8   \n",
      " 200 SaleCondition_Family   uint8   \n",
      " 201 SaleCondition_Normal   uint8   \n",
      " 202 SaleCondition_Partial  uint8   \n",
      " 203 Set                    category\n",
      "dtypes: category(1), float64(11), int64(31), uint8(161)\n",
      "memory usage: 1.4 MB\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def mergeTrainAndTest(train, test):\n",
    "    trainToMerge = train.copy()\n",
    "    Ytrain = trainToMerge['SalePrice'] \n",
    "    trainToMerge.drop(labels = 'SalePrice', axis = 1, inplace = True)\n",
    "    trainToMerge['Set'] = 'train'\n",
    "    testToMerge = test.copy()\n",
    "    testToMerge['Set'] = 'test'\n",
    "    db = trainToMerge.copy()\n",
    "    db = db.append(testToMerge)\n",
    "    return db, Ytrain\n",
    "\n",
    "def convertToCategories(db):\n",
    "    db['MSSubClass'] = db['MSSubClass'].astype('category')\n",
    "    db[\"ExterQual\"] = db[\"ExterQual\"].map({'Ex': 5, 'Gd': 4, 'TA': 3, 'Fa': 2, 'Po': 1})\n",
    "    db[\"ExterCond\"] = db[\"ExterCond\"].map({'Ex': 5, 'Gd': 4, 'TA': 3, 'Fa': 2, 'Po': 1})\n",
    "    db[\"BsmtQual\"] = db[\"BsmtQual\"].map({'Ex': 5, 'Gd': 4, 'TA': 3, 'Fa': 2, 'Po': 1, 'NA': 0})\n",
    "    db[\"BsmtCond\"] = db[\"BsmtCond\"].map({'Ex': 5, 'Gd': 4, 'TA': 3, 'Fa': 2, 'Po': 1, 'NA': 0})\n",
    "    db[\"BsmtExposure\"] = db[\"BsmtExposure\"].map({'Gd': 4, 'Av': 3, 'Mn': 2, 'No': 1, 'NA': 0})\n",
    "    db[\"HeatingQC\"] = db[\"HeatingQC\"].map({'Ex': 5, 'Gd': 4, 'TA': 3, 'Fa': 2, 'Po': 1})\n",
    "    db[\"KitchenQual\"] = db[\"KitchenQual\"].map({'Ex': 5, 'Gd': 4, 'TA': 3, 'Fa': 2, 'Po': 1})\n",
    "    db[\"FireplaceQu\"] = db[\"FireplaceQu\"].map({'Ex': 5, 'Gd': 4, 'TA': 3, 'Fa': 2, 'Po': 1, 'NA': 0})\n",
    "    db[\"GarageQual\"] = db[\"GarageQual\"].map({'Ex': 5, 'Gd': 4, 'TA': 3, 'Fa': 2, 'Po': 1, 'NA': 0})\n",
    "    db[\"GarageCond\"] = db[\"GarageCond\"].map({'Ex': 5, 'Gd': 4, 'TA': 3, 'Fa': 2, 'Po': 1, 'NA': 0})\n",
    "    for i in db.select_dtypes(include='object').columns.to_list():\n",
    "        db[i] = db[i].astype('category')\n",
    "        \n",
    "def oneHotEncoding(db):\n",
    "    typeOfSet = db['Set']\n",
    "    db.drop(labels = 'Set', axis = 1, inplace = True)\n",
    "    featuresToEncode = db.select_dtypes(include='category').head().columns.values.tolist()\n",
    "    resultantDB = pd.get_dummies(db, columns = featuresToEncode, drop_first= True)\n",
    "    resultantDB = pd.concat([resultantDB, typeOfSet], axis=1)\n",
    "    return resultantDB\n",
    "\n",
    "db, Ytrain = mergeTrainAndTest(train, test)\n",
    "convertToCategories(db)\n",
    "\n",
    "db = oneHotEncoding(db)\n",
    "\n",
    "db.info(verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X train obtenido\n",
      "(1460, 203)\n",
      "X test obtenido\n",
      "(1452, 203)\n",
      "Y train obtenido\n",
      "(1460,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jorge/anaconda3/lib/python3.7/site-packages/pandas/core/frame.py:3997: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  errors=errors,\n",
      "/home/jorge/anaconda3/lib/python3.7/site-packages/pandas/core/frame.py:3997: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  errors=errors,\n"
     ]
    }
   ],
   "source": [
    "def separateTestAndTrain(db):\n",
    "    \n",
    "    Xtrain = db.loc[db['Set'] == 'train']\n",
    "    Xtrain.drop(labels = 'Set', axis = 1, inplace = True)\n",
    "    Xtest = db.loc[db['Set'] == 'test']\n",
    "    Xtest.drop(labels = 'Set', axis = 1, inplace = True)\n",
    "    return Xtrain, Xtest\n",
    "\n",
    "Xtrain, Xtest = separateTestAndTrain(db)\n",
    "\n",
    "\n",
    "print(\"X train obtenido\")\n",
    "print(Xtrain.shape)\n",
    "\n",
    "print(\"X test obtenido\")\n",
    "print(Xtest.shape)\n",
    "\n",
    "print(\"Y train obtenido\")\n",
    "print(Ytrain.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Nota</b>: Agregue una celda en la cual incluya las líneas de código usadas para responder las preguntas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Arboles de decisión\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Obtener parametros con validación\n",
    "#Entrenar con esos parametros el conjunto de entrenamiento\n",
    "#Evaluar desempeño con el conjuntk de test\n",
    "\n",
    "#Separa conjunto de entrenamiento y validación del conjunto de test\n",
    "X_train_val, X_test, y_train_val, y_test = train_test_split(Xtrain, Ytrain, test_size=0.10, shuffle=True)\n",
    "\n",
    "#Separar entrenamiento del conjunto de validación\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train_val, y_train_val, test_size=0.20, shuffle=True)\n",
    "\n",
    "#SEGUNDO INTENTO\n",
    "\n",
    "#Separa conjunto de entrenamiento y test del de validación\n",
    "X_train_test, X_val, y_train_test, y_val = train_test_split(Xtrain, Ytrain, test_size=0.10, shuffle=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 436,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'criterion': 'mae',\n",
       " 'max_depth': 4,\n",
       " 'max_features': 'auto',\n",
       " 'min_samples_split': 2,\n",
       " 'n_estimators': 500}"
      ]
     },
     "execution_count": 436,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Mejores hiperparametros obtenidos con conjunto de validación\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "n_estimators = [100,150, 200,300,400,500]\n",
    "max_features = ['auto', 'sqrt', 'log2']\n",
    "max_depth = [3,4]\n",
    "min_samples_split = [0.1]\n",
    "criterion = [\"mse\", \"mae\"]\n",
    "min_samples_split = [2,4,6,8,10,20]\n",
    "\n",
    "\n",
    "random_grid = {'n_estimators': n_estimators,\n",
    "               'max_features': max_features,\n",
    "               'max_depth': max_depth,\n",
    "               'min_samples_split': min_samples_split,\n",
    "               'criterion': criterion,\n",
    "               'min_samples_split' : min_samples_split}\n",
    "\n",
    "regr = RandomForestRegressor()\n",
    "regr_random = GridSearchCV(estimator = regr, param_grid = random_grid, cv = 3)\n",
    "regr_random.fit(X_val, y_val)\n",
    "\n",
    "regr_random.best_params_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 437,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conjunto de validación\n",
      "rmse  1576606166.2391498\n",
      "mae  24009.992557701833\n",
      "mape 13.531225719496245\n",
      "r2 0.7610663654162971\n",
      "Accuracity  86.46877428050375\n",
      "Conjunto de Entramiento\n",
      "rmse_train  1402965368.4909132\n",
      "mae_train  22985.295619075634\n",
      "mape_train  13.55106652594125\n",
      "r2_train 0.7790760887800163\n",
      "Accuracity  86.44893347405875\n"
     ]
    }
   ],
   "source": [
    "#Entrenamientocon conjunto de train con hiperparametros obtenidos con el conjunto de validación\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import r2_score\n",
    "import numpy as np\n",
    "\n",
    "def mean_absolute_percentage_error(y_true, y_pred): \n",
    "    y_true, y_pred = np.array(y_true), np.array(y_pred)\n",
    "    return np.mean(np.abs((y_true - y_pred) / y_true)) * 100\n",
    "\n",
    "\n",
    "\n",
    "regr = RandomForestRegressor(max_depth=4, random_state=0, n_estimators=500, min_samples_split=0.1,max_features='auto', criterion='mse')\n",
    "regr.fit(X_train, y_train)\n",
    "\n",
    "Ytrain_est = regr.predict(X_train) \n",
    "Yest = regr.predict(X_val) \n",
    "\n",
    "rmse = mean_squared_error(y_val, Yest, squared=True)\n",
    "mae = mean_absolute_error(y_val, Yest)\n",
    "mape = mean_absolute_percentage_error(y_val, Yest)\n",
    "r2 = r2_score(y_val, Yest)\n",
    "print(\"Conjunto de validación\")\n",
    "print('rmse ',rmse)\n",
    "print('mae ', mae)\n",
    "print('mape', mape)\n",
    "print('r2', r2)\n",
    "print('Accuracity ', 100 - mape)\n",
    "\n",
    "\n",
    "rmse_train = mean_squared_error(y_train, Ytrain_est, squared=True)\n",
    "mae_train = mean_absolute_error(y_train, Ytrain_est)\n",
    "mape_train = mean_absolute_percentage_error(y_train, Ytrain_est)\n",
    "r2_train = r2_score(y_train, Ytrain_est)\n",
    "\n",
    "print(\"Conjunto de Entramiento\")\n",
    "print('rmse_train ',rmse_train)\n",
    "print('mae_train ', mae_train)\n",
    "print('mape_train ', mape_train)\n",
    "print('r2_train', r2_train)\n",
    "print('Accuracity ', 100 - mape_train)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 435,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.81942603 0.65826003 0.81932011 0.76635798 0.65874044]\n",
      "0.07277600361361364\n",
      "0.7444209171378491\n"
     ]
    }
   ],
   "source": [
    "#Entramiento con metodología de validación usando los mejores hiperparametros, datos de entranmiento\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "import numpy as np\n",
    "#sklearn.metrics.mean_squared_error¶\n",
    "\n",
    "\n",
    "regr = RandomForestRegressor(max_depth=4, random_state=0, n_estimators=100, min_samples_split=0.1,max_features='auto', criterion='mse')\n",
    "regr.fit( X_train, y_train);\n",
    "scores = cross_val_score(regr, X_train, y_train, cv=5, scoring='r2') #Score mse cross_val_predict\n",
    "print(scores)\n",
    "\n",
    "print(np.std(scores))\n",
    "\n",
    "print(np.mean(scores))\n",
    "                            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.85355509 0.80682217 0.85545633 0.427155   0.88715541]\n",
      "0.17136472336729028\n",
      "0.7660288001465487\n"
     ]
    }
   ],
   "source": [
    "#Entramiento con metodología de validación usando los mejores hiperparametros, datos de test\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "regr = RandomForestRegressor(max_depth=4, random_state=0, n_estimators=100, min_samples_split=0.1,max_features='auto', criterion='mse')\n",
    "scores = cross_val_score(regr, X_test, y_test, cv=5, scoring='r2')\n",
    "print(scores)\n",
    "\n",
    "cv_score = np.sqrt(-cross_val_score(estimator=regr, X=X_test, y=y_test, cv=100, scoring = scorer))\n",
    "\n",
    "\n",
    "print(np.std(scores))\n",
    "print(np.mean(scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23118.302888173264\n",
      "0.7681164839160279\n"
     ]
    }
   ],
   "source": [
    "print(np.std(cv_score))\n",
    "print(np.mean(scores))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conjunto de validación\n",
      "rmse  1450033068.4197078\n",
      "mae  26289.039927799007\n",
      "mape 15.230270479081684\n",
      "r2 0.7413010817561191\n",
      "Accuracity  84.76972952091832\n"
     ]
    }
   ],
   "source": [
    "#Desempeño del modelo con datos de test\n",
    "\n",
    "Yest = regr.predict(X_test) \n",
    "\n",
    "rmse = mean_squared_error(y_test, Yest, squared=True)\n",
    "mae = mean_absolute_error(y_test, Yest)\n",
    "mape = mean_absolute_percentage_error(y_test, Yest)\n",
    "r2 = r2_score(y_test, Yest)\n",
    "print(\"Conjunto de validación\")\n",
    "print('rmse ',rmse)\n",
    "print('mae ', mae)\n",
    "print('mape', mape)\n",
    "print('r2', r2)\n",
    "print('Accuracity ', 100 - mape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'GridSearchCV' object has no attribute 'std_test_score'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-192-33bb51b0b54d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mregr_random\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstd_test_score\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'GridSearchCV' object has no attribute 'std_test_score'"
     ]
    }
   ],
   "source": [
    "#Con datos de test (borrar)\n",
    "\n",
    "regr = RandomForestRegressor(max_depth=4, random_state=0, n_estimators=300, min_samples_split=0.1,max_features='auto', criterion='mae')\n",
    "regr.fit(X_test, y_test)\n",
    "\n",
    "Ytrain_est = regr.predict(X_train) \n",
    "Yest = regr.predict(X_val) \n",
    "\n",
    "rmse = mean_squared_error(y_val, Yest, squared=True)\n",
    "mae = mean_absolute_error(y_val, Yest)\n",
    "mape = mean_absolute_percentage_error(y_val, Yest)\n",
    "r2 = r2_score(y_val, Yest)\n",
    "print(\"Conjunto de validación\")\n",
    "print('rmse ',rmse)\n",
    "print('mae ', mae)\n",
    "print('mape', mape)\n",
    "print('r2', r2)\n",
    "print('Accuracity ', 100 - mape)\n",
    "\n",
    "\n",
    "rmse_train = mean_squared_error(y_train, Ytrain_est, squared=True)\n",
    "mae_train = mean_absolute_error(y_train, Ytrain_est)\n",
    "mape_train = mean_absolute_percentage_error(y_train, Ytrain_est)\n",
    "r2_train = r2_score(y_train, Ytrain_est)\n",
    "\n",
    "print(\"Conjunto de Entramiento\")\n",
    "print('rmse_train ',rmse_train)\n",
    "print('mae_train ', mae_train)\n",
    "print('mape_train ', mape_train)\n",
    "print('r2_train', r2_train)\n",
    "print('Accuracity ', 100 - mape_train)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regresion por Vectores de Soporte con kernel lineal y con kernel RBF."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Medidas de error\n",
    "\n",
    "def errorMeasure(y_train, y_pred):\n",
    "    \n",
    "    rmse = mean_squared_error(y_train, y_pred, squared=True)\n",
    "    mae = mean_absolute_error(y_train, y_pred)\n",
    "    mape = mean_absolute_percentage_error(y_train, y_pred)\n",
    "    r2 = r2_score(y_train, y_pred)\n",
    "    \n",
    "    return {'rmse': rmse, 'mae': mae, 'mape': mape, 'r2': r2}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Normalizar los datos\n",
    "\n",
    "from sklearn import preprocessing\n",
    "normalize = preprocessing.StandardScaler().fit(X_train)\n",
    "X_train_N = normalize.transform(X_train)\n",
    "X_test_N = normalize.transform(X_test)  \n",
    "\n",
    "normalize = preprocessing.StandardScaler().fit(X_val)\n",
    "X_val_N = normalize.transform(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Obtener hiperparametros con conjunto de validación\n",
    "\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "def SVR_validation(kernel):  \n",
    "    gamma = [0.001, 0.01, 0.1, 1]\n",
    "    C = [0.001, 0.01,0.1,1,10,100, 200, 300, 500]\n",
    "    epsilon= [0.2, 1]\n",
    "\n",
    "    svr_grid = {'C': C,\n",
    "               'epsilon': epsilon,\n",
    "               'gamma' : gamma}\n",
    "\n",
    "    srv = SVR(kernel=kernel)\n",
    "    regr_svr = GridSearchCV(estimator = srv, param_grid = svr_grid, cv = 10)\n",
    "    regr_svr.fit(X_val_N, y_val)\n",
    "\n",
    "    return regr_svr.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 100, 'epsilon': 0.2, 'gamma': 0.001}\n",
      "performanceTrain\n",
      "{'rmse': 6188458788.159143, 'mae': 54113.20887879129, 'mape': 31.19577851692446, 'r2': -0.015709948189657874}\n",
      "performanceTest\n",
      "{'rmse': 6199692559.530962, 'mae': 51853.48392348294, 'mape': 26.958470470630374, 'r2': -0.0543405921440967}\n"
     ]
    }
   ],
   "source": [
    "from sklearn import preprocessing\n",
    "\n",
    "#RBF Para el mejor valor, toca realizarlo con Kfold\n",
    "params = SVR_validation('rbf')\n",
    "print(params)\n",
    "\n",
    "regr = SVR(C = params['C'], epsilon = params['epsilon'], gamma =params['gamma'], kernel = 'rbf')\n",
    "regr.fit(X_train_N, y_train)\n",
    "\n",
    "y_pred_train_SVR = regr.predict(X_train_N) #Entrenamiento con datos normalizados\n",
    "\n",
    "#Desempeño del modelo con datos de entrenamiento\n",
    "\n",
    "performanceTrain = errorMeasure(y_train, y_pred_train_SVR)\n",
    "print('performanceTrain')\n",
    "print(performanceTrain)\n",
    "\n",
    "y_est_test = regr.predict(X_test_N) #Entrenamiento con datos normalizados\n",
    "\n",
    "#Desempeño del modelo con datos de test\n",
    "\n",
    "performanceTest = errorMeasure(y_test, y_est_test)\n",
    "print('performanceTest')\n",
    "print(performanceTest)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 300, 'epsilon': 1, 'gamma': 0.001}\n",
      "performanceTrain\n",
      "{'rmse': 540163238.4501314, 'mae': 13051.005964047568, 'mape': 7.45078811894427, 'r2': 0.9113431641509977}\n",
      "performanceTest\n",
      "{'rmse': 2771506852.287864, 'mae': 21438.05223140149, 'mape': 12.684426251268313, 'r2': 0.5286682125421909}\n"
     ]
    }
   ],
   "source": [
    "from sklearn import preprocessing\n",
    "\n",
    "#RBF Para el mejor valor, toca realizarlo con Kfold\n",
    "params = SVR_validation('linear')\n",
    "print(params)\n",
    "\n",
    "regr = SVR(C = params['C'], epsilon = params['epsilon'], kernel = 'linear')\n",
    "regr.fit(X_train_N, y_train)\n",
    "\n",
    "y_pred_train_SVR = regr.predict(X_train_N) #Entrenamiento con datos normalizados\n",
    "\n",
    "#Desempeño del modelo con datos de entrenamiento\n",
    "\n",
    "performanceTrain = errorMeasure(y_train, y_pred_train_SVR)\n",
    "print('performanceTrain')\n",
    "print(performanceTrain)\n",
    "\n",
    "y_est_test = regr.predict(X_test_N) #Entrenamiento con datos normalizados\n",
    "\n",
    "#Desempeño del modelo con datos de test\n",
    "\n",
    "performanceTest = errorMeasure(y_test, y_est_test)\n",
    "print('performanceTest')\n",
    "print(performanceTest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio 2: Completar código \n",
    "\n",
    "Analice los siguientes métodos de la teoría vista para los modelos de *regresión polinomial múltiple*, tales como el error cuadrático medio (<font color='blue'>ECM</font>), modelo de regresión múltiple (<font color='blue'>regression</font>), potencia del polinomio (<font color='blue'>potenciaPolinomio</font>) y gradiente descendente. \n",
    "\n",
    "Una vez comprenda su funcionamiento proceda a realizar lo siguiente: \n",
    "1. Completar el código de la regla de actualización de los parámetros del algoritmo de <font color='blue'>gradiente_descedente</font>: \n",
    "\n",
    "$$w_j(iter) = w_j(iter-1) - \\eta \\frac{\\partial E(w)}{\\partial w_j}$$ \n",
    "\n",
    "2. Graficar el error cuadrático: Error cuadrático medio (ECM) vs. las iteraciones del algoritmo. La gráfica debe llevar título y los correspondientes nombres de los ejes, puedes consultar documentación [aquí](https://matplotlib.org/tutorials/introductory/pyplot.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Error cuadrático medio (criterio para el modelo de regresión polinomial)\n",
    "def ECM(Y_est,Y):\n",
    "    N = np.size(Y)\n",
    "    ecm = np.sum((Y_est.reshape(N,1) - Y.reshape(N,1))**2)/(2*N)\n",
    "    return ecm \n",
    "\n",
    "#Modelo Regresión Múltiple\n",
    "def regression(X, W):\n",
    "    Yest = np.dot(X,W)    #con np.dot se realiza el producto matricial. Aquí X es dim [Nxd] y W es dim [dx1]\n",
    "    return Yest           #Esta variable contiene la salida de f(X,W)\n",
    "\n",
    "#Potencia de polinomio\n",
    "\n",
    "def potenciaPolinomio(X,grado):\n",
    "    X2 = X\n",
    "    \n",
    "    if grado != 1:\n",
    "        for i in range(2,grado+1):\n",
    "            Xadd = X**i\n",
    "            X2 = np.concatenate((X2, Xadd), axis=1)\n",
    "    return X2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Gradiente descendente para regresión lineal múltiple\n",
    "X: Matriz de datos extendida.\n",
    "W: Vector de parámetros del modelo\n",
    "eta: Taza de aprendizaje\n",
    "\"\"\"\n",
    "#X es db que son los datos de tamaño (9357, 13),\n",
    "#Y \n",
    "#eta es la tasa de aprendizaje\n",
    "def gradiente_descendente(X,Y,eta):\n",
    "     \n",
    "    #Extendemos la matriz de X para el parámetro independiente\n",
    "    unos = np.array([np.ones(np.size(X,0))])\n",
    "    #Concatenamos el vector de unos con la matriz X\n",
    "    X = np.concatenate((unos.T, X), axis=1)\n",
    "    X = X.reshape(np.size(X,0),np.size(X,1))                 #Una forma de concatenar\n",
    "    \n",
    "    Y = Y.reshape(np.size(Y), 1)\n",
    "    \n",
    "    #Tomamos el número de variables del problema\n",
    "    d = np.size(X,1)\n",
    "    \n",
    "    #Tomamos el número de muestras de la base de datos\n",
    "    N = np.size(X,0)\n",
    "    \n",
    "    \n",
    "    #Inicializamos el vector de parámetros \n",
    "    W = np.zeros((1,d))\n",
    "    W = W.reshape(np.size(W), 1)\n",
    "    \n",
    "    eta = eta\n",
    "    \n",
    "    iteraciones = 500\n",
    "    ecms = np.zeros(iteraciones)\n",
    "    \n",
    "    print('X', X)\n",
    "    \n",
    "    #Aquí se completa el código\n",
    "    for iter in range(iteraciones):\n",
    "        t1 = regression(X, W)\n",
    "        ecms[iter] = ECM(t1,Y)\n",
    "        t2 = t1 - Y\n",
    "        t3 = regression(X.T,t2)\n",
    "        W = W - eta*t3/N\n",
    "    print ('Vector de parámetros del modelo:\\n')\n",
    "    print (W)\n",
    "    print ('\\nError Final durante el entrenamiento = ' + str(ecms[-1]))\n",
    "    \n",
    "    #Aquí debe completar el código para realizar la gráfica de ecms vs. iteraciones\n",
    "    plt.plot(ecms) #.plot al mandarle el vector de errores realizara la gráfica considerando el índice como valor del eje X y en el eje Y considerara el valor en ese posición.\n",
    "    plt.xlabel('Iteraciones')\n",
    "    plt.ylabel('ECM')\n",
    "    plt.show()\n",
    "    \n",
    "    return W\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "regr_freq = LinearRegression()\n",
    "regr_freq.fit(Xtrain, Ytrain)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio 3: Entrenamiento\n",
    "\n",
    "En este punto debe hacer uso de las funciones escritas en el punto anterior para realizar el proceso de *modelamiento y simulación* de los datos de cargados en el Ejercicio # 1 sobre la predicción del valor de la humedad absoluta en el aire \n",
    "\n",
    "A continuación complete el siguiente código llamando a la función <font color='blue'>gradiente_descedente</font> pasandole los parámetros correspondientes (X,y,eta). Debe obtener como salida el vector de parámetros $w$ estimado y la gráfica del error cuadrático medio vs iteraciones.\n",
    "\n",
    "*Nota*: No olvide definir el grado del polinomio y la taza de aprendizaje (eta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE is: 32634.65\n",
      "R_squared is 84.14%\n",
      "dict_keys(['copy_X', 'fit_intercept', 'n_jobs', 'normalize'])\n",
      "Fitting 10 folds for each of 80 candidates, totalling 800 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sady/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_split.py:657: Warning: The least populated class in y has only 1 members, which is too few. The minimum number of members in any class cannot be less than n_splits=10.\n",
      "  % (min_groups, self.n_splits)), Warning)\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done 348 tasks      | elapsed:    2.6s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score: 0.760371 using {'copy_X': True, 'fit_intercept': True, 'n_jobs': 1, 'normalize': False}\n",
      "Despues (array([], dtype=int64), array([], dtype=int64))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 800 out of 800 | elapsed:    5.3s finished\n",
      "/home/sady/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_search.py:814: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import StratifiedKFold, GridSearchCV\n",
    "from numpy import random\n",
    "import math\n",
    "\n",
    "X = Xtrain.values\n",
    "Y = Ytrain.values\n",
    "\n",
    "# #Se modifica la matriz de datos original de acuerdo al grado del polinomio ingresado para el modelo\n",
    "grado = 1\n",
    "X2 = potenciaPolinomio(X,grado)\n",
    "\n",
    "random.seed(1)\n",
    "#print(np.any(np.isnan(X)))\n",
    "#print(np.all(np.isfinite(X)))\n",
    "\n",
    "\n",
    "Xtraining, Xtesting, Ytraining, Ytesting = train_test_split(X, Y, test_size=0.25)\n",
    "\n",
    "regr_freq = LinearRegression()\n",
    "regr_freq.fit(Xtraining, Ytraining)\n",
    "print(\"RMSE is: {:.2f}\\nR_squared is {:.2f}%\".format(math.sqrt(np.mean((regr_freq.predict(Xtesting) - Ytesting) ** 2)),\n",
    "                                                   regr_freq.score(Xtesting,Ytesting)*100))\n",
    "\n",
    "kfold = StratifiedKFold(n_splits = 10, shuffle = True, random_state = 10)\n",
    "print(regr_freq.get_params().keys())\n",
    "fit_intercept=[True, False]\n",
    "normalize=[True, False]\n",
    "copy_X=[True,False]\n",
    "n_jobs=[1,2,3,4,5,6,7,8,9,10]\n",
    "param_grid = dict(copy_X=copy_X, fit_intercept=fit_intercept, normalize=normalize, n_jobs=n_jobs)\n",
    "grid_search_xg_freq = GridSearchCV(regr_freq, param_grid, scoring = 'r2', n_jobs = -1, cv=kfold, verbose = 1)\n",
    "result_gcv_xgb_freq = grid_search_xg_freq.fit(Xtraining, Ytraining.astype(int))\n",
    "print(\"Best score: %f using %s\" % (result_gcv_xgb_freq.best_score_, result_gcv_xgb_freq.best_params_))\n",
    "means = result_gcv_xgb_freq.cv_results_['mean_test_score']\n",
    "stds = result_gcv_xgb_freq.cv_results_['std_test_score']\n",
    "params = result_gcv_xgb_freq.cv_results_['params']\n",
    "#print(np.any(np.isnan(Xtraining)))\n",
    "#print(np.all(np.isfinite(Xtraining)))\n",
    "\n",
    "eta = 1e-2\n",
    "\n",
    "print('Despues', np.where(np.isnan(Xtraining)))\n",
    "regr_freq = LinearRegression()\n",
    "regr_freq.fit(Xtraining, Ytraining)\n",
    "W = regr_freq.predict(Xtesting)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Responda:\n",
    "\n",
    "3.1 ¿Cuál es el número de coeficientes $w$ que se obtienen al ingresar un polinomio de grado 4? ¿Por qué?:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grado = 4\n",
    "size = np.size(potenciaPolinomio(X, grado),1)\n",
    "terminoIndependiente = 1\n",
    "realSize = size + terminoIndependiente\n",
    "print(realSize)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.2 La funci&oacute;n polin&oacute;mica que se est&aacute; usando para grados mayores a 1\n",
    "est&aacute; incompleta, ¿Por qu&eacute;?:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Debido a que falta el producto entre caracteristicas que resulta de extender la expresión polinomica a un grado mayor a uno."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio 4: Obtener resultados\n",
    "\n",
    "Identifique la variable \"eta\" (tasa de aprendizaje $\\eta$) en el código anterior, cambie su valor de acuerdo a la siguiente tabla. Haga lo mismo con el valor del grado del polinomio y complete las columnas ECM_Entrenamiento y ECM_Prueba.\n",
    "\n",
    "Tenga en cuenta que cuando el valor de $\\eta$ sea $0.00001$ y el grado del polinomio sea $1$, el valor del ECM de prueba debe ser $703.376$. Esto le servirá de criterio de verificación para la implementación de su algorítmo de gradiente descendente.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3d005685544a4eeb9b05a0f3d8e192d7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "QgridWidget(grid_options={'fullWidthRows': True, 'syncColumnCellResize': True, 'forceFitColumns': True, 'defau…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import qgrid as qg\n",
    "randn = np.random.randn\n",
    "df_types = pd.DataFrame({\n",
    "    'Tasa de aprendizaje' : pd.Series(['1e-5', '1e-5', '1e-5', '1e-5', '1e-5', '1e-3', '1e-3', '1e-3', '1e-3', '1e-3', '1e-1', '1e-1', '1e-1', '1e-1', '1e-1']),\n",
    "    'Grado del polinomio' : pd.Series([1,2,3,4,5,1,2,3,4,5,1,2,3,4,5])})\n",
    "df_types[\"ECM_Entrenamiento\"] = \"\"\n",
    "df_types[\"ECM_Prueba\"] = \"\"\n",
    "df_types.set_index(['Tasa de aprendizaje','Grado del polinomio'], inplace=True)\n",
    "df_types[\"ECM_Entrenamiento\"][0] = \"774.055\"\n",
    "df_types[\"ECM_Prueba\"][0] = \"703.376\"\n",
    "df_types.sort_index(inplace=True)\n",
    "qgrid_widget = qg.show_grid(df_types, show_toolbar=False)\n",
    "qgrid_widget"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ejecute la siguiente instrucción para dejar guardados en el notebook los resultados de las pruebas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qgrid_widget.get_changed_df()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio 5: Pruebas\n",
    "\n",
    "En la celda de código del Ejercicio # 3, comente la línea donde se normalizan las matrices de datos Xtrain y Xtest. Realice pruebas para diferentes valores de $\\eta$ y de grado del polinomio de manera similar a los valores que usó en el punto 3. Observe que pasa con el ECM.\n",
    "\n",
    "#### Responda\n",
    "\n",
    "5.1 ¿Qué sucede con los valores del ECM?\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los valores del ECM se desbordan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5.2 ¿A qué se debe lo que observa?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Debido a que la convergencia entre caracteristicas se reduce por falta de normalización"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5.3.1 ¿Qu&eacute; proceso hace la normalizaci&oacute;n sobre los datos? \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cambia los valores del dataset a una escala común sin distorsionar las diferencias en los rangos de valores."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5.3.2 Consulte por qu&eacute; es necesaria la normalizaci&oacute;n en el modelo de regresi&oacute;n  y cu&aacute;les son los tipos de normalizaci&oacute;n m&aacute;s comunes. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Es necesaria porque es posible que algunas características sean cuantitativamente mucho mayores que las demás lo que puede causar que contribuyan a la variación en el término independiente aunque no necesariamente sean más importantes. Algunos de los métodos de normalización son: decimal scaling, min-max normalization y z-score."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5.3.3 ¿Cu&aacute;l de ellos se aplic&oacute; en el laboratorio?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El método utilizado en este laboratorio fue z-score. \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
