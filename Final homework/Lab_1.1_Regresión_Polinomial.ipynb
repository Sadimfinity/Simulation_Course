{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Laboratorio 1 - Parte 1\n",
    "\n",
    "### Regresión polinomial múltiple\n",
    "\n",
    "### 2019 - II\n",
    "\n",
    "#### Profesor: Julián D. Arias Londoño\n",
    "#### julian.ariasl@udea.edu.co\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Guía del laboratorio\n",
    "\n",
    "En este archivo va a encontrar tanto celdas de código como celdas de texto con las instrucciones para desarrollar el laboratorio.\n",
    "\n",
    "Lea atentamente las instrucciones entregadas en las celdas de texto correspondientes y proceda con la solución de las preguntas planteadas.\n",
    "\n",
    "Nota: no olvide ir ejecutando las celdas de código de arriba hacia abajo para que no tenga errores de importación de librerías o por falta de definición de variables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Primer integrante:\n",
    "Nombre: Jorge Hiler Ricardo\n",
    "\n",
    "\n",
    "#### Segundo integrante:\n",
    "\n",
    "Nombre: Santiago Gaviria Zapata\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['LotFrontage', 'MasVnrType', 'MasVnrArea', 'BsmtQual', 'BsmtCond', 'BsmtExposure', 'BsmtFinType1', 'BsmtFinType2', 'Electrical', 'FireplaceQu', 'GarageType', 'GarageYrBlt', 'GarageFinish', 'GarageQual', 'GarageCond']\n",
      "['MSZoning', 'LotFrontage', 'MasVnrType', 'MasVnrArea', 'BsmtQual', 'BsmtCond', 'BsmtExposure', 'BsmtFinType1', 'BsmtFinSF1', 'BsmtFinType2', 'BsmtFinSF2', 'BsmtUnfSF', 'TotalBsmtSF', 'BsmtFullBath', 'BsmtHalfBath', 'FireplaceQu', 'GarageType', 'GarageYrBlt', 'GarageFinish', 'GarageCars', 'GarageArea', 'GarageQual', 'GarageCond']\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import numpy.matlib as npMatlib\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "#from scipy import stats\n",
    "\n",
    "#Algunas advertencias que queremos evitar\n",
    "import warnings\n",
    "warnings.filterwarnings(\"always\")\n",
    "\n",
    "train = pd.read_csv(r'DB/train.csv')\n",
    "\n",
    "test = pd.read_csv(r'DB/test.csv')\n",
    "\n",
    "naTrainResultantColumns = train.columns[train.isna().any()].tolist()\n",
    "naTestColumns = test.columns[test.isna().any()].tolist()\n",
    "print(naTrainResultantColumns)\n",
    "print(naTestColumns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio 1: Contextualización del problema\n",
    "\n",
    "El problema de *regresión* que abordaremos consiste en predecir el valor de la humedad absoluta en el aire, a partir de varias variables sensadas en el aire (Para más información sobre la base de datos y la contextualización del problema, consulte: http://archive.ics.uci.edu/ml/datasets/air+quality). Ejecute la siguiente celda para cargar los datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numero de columnas con valores NA:  0\n",
      "Numero de columnas con valores NA:  0\n",
      "Lllenado de campos vacíos completado\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "def fillNAs(train, test):\n",
    "    naTrainColumns = train.columns[train.isna().any()].tolist()\n",
    "    train[naTrainColumns[0]].fillna(train[naTrainColumns[0]].mean(), inplace = True)\n",
    "    train[naTrainColumns[1]].fillna('None', inplace = True)\n",
    "    train[naTrainColumns[2]].fillna(train[naTrainColumns[2]].mean(), inplace = True)\n",
    "    train[naTrainColumns[3]].fillna('NA', inplace = True)\n",
    "    train[naTrainColumns[4]].fillna('NA', inplace = True)\n",
    "    train[naTrainColumns[5]].fillna('NA', inplace = True)\n",
    "    train[naTrainColumns[6]].fillna('NA', inplace = True)\n",
    "    train[naTrainColumns[7]].fillna('NA', inplace = True)\n",
    "    train[naTrainColumns[8]].fillna('SBrkr', inplace = True)\n",
    "    train[naTrainColumns[9]].fillna('NA', inplace = True)\n",
    "    train[naTrainColumns[10]].fillna('NA', inplace = True)\n",
    "    train[naTrainColumns[11]].fillna(train[naTrainColumns[11]].mean(), inplace = True)\n",
    "    train[naTrainColumns[12]].fillna('NA', inplace = True)\n",
    "    train[naTrainColumns[13]].fillna('NA', inplace = True)\n",
    "    train[naTrainColumns[14]].fillna('NA', inplace = True)\n",
    "    \n",
    "    naTrainResultantColumns = train.columns[train.isna().any()].size\n",
    "    print('Numero de columnas con valores NA: ', naTrainResultantColumns)\n",
    "    \n",
    "    naTestColumns = test.columns[test.isna().any()].tolist()\n",
    "    \n",
    "    test[naTestColumns[0]].fillna('RL', inplace = True)\n",
    "    test[naTestColumns[1]].fillna(test[naTestColumns[1]].mean(), inplace = True)\n",
    "    test[naTestColumns[2]].fillna('None', inplace = True)\n",
    "    test[naTestColumns[3]].fillna(test[naTestColumns[3]].mean(), inplace = True)\n",
    "    test[naTestColumns[4]].fillna('NA', inplace = True)\n",
    "    test[naTestColumns[5]].fillna('NA', inplace = True)\n",
    "    test[naTestColumns[6]].fillna('NA', inplace = True)\n",
    "    test[naTestColumns[7]].fillna('NA', inplace = True)\n",
    "    test[naTestColumns[8]].fillna(test[naTestColumns[8]].mean(), inplace = True)\n",
    "    test[naTestColumns[9]].fillna('NA', inplace = True)\n",
    "    test[naTestColumns[10]].fillna(test[naTestColumns[10]].mean(), inplace = True)\n",
    "    test[naTestColumns[11]].fillna(test[naTestColumns[11]].mean(), inplace = True)\n",
    "    test[naTestColumns[12]].fillna(test[naTestColumns[12]].mean(), inplace = True)\n",
    "    test[naTestColumns[13]].fillna(test[naTestColumns[13]].mean(), inplace = True)\n",
    "    test[naTestColumns[14]].fillna(test[naTestColumns[14]].mean(), inplace = True)\n",
    "    test[naTestColumns[15]].fillna('NA', inplace = True)\n",
    "    test[naTestColumns[16]].fillna('NA', inplace = True)\n",
    "    test[naTestColumns[17]].fillna(test[naTestColumns[17]].mean(), inplace = True)\n",
    "    test[naTestColumns[18]].fillna('NA', inplace = True)\n",
    "    test[naTestColumns[19]].fillna(round(float(test[naTestColumns[19]].mean()), 1), inplace = True)\n",
    "    test[naTestColumns[20]].fillna(test[naTestColumns[20]].mean(), inplace = True)\n",
    "    test[naTestColumns[21]].fillna('NA', inplace = True)\n",
    "    test[naTestColumns[22]].fillna('NA', inplace = True)\n",
    "    \n",
    "    naTestResultantColumns = train.columns[train.isna().any()].size\n",
    "    print('Numero de columnas con valores NA: ', naTestResultantColumns)\n",
    "    \n",
    "    if (naTrainResultantColumns == 0 & naTestResultantColumns == 0):\n",
    "        return print(\"Lllenado de campos vacíos completado\")\n",
    "    else: \n",
    "        return print(\"Llenado de campos vacíos erróneo\")\n",
    "\n",
    "fillNAs(train, test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Responda:\n",
    "\n",
    "1.1 Cuántas muestras tiene la base de datos?: \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Deleted columns 'cause had a lot of NA > 80%: 'Alley','Fence','MiscFeature','PoolQC'\n",
    "#Deleted columns 'cause the std = 0: 'Utilities' %rep = 1, 'Street' %rep =1,\n",
    "#'LandSlope' %rep = 0.95, Condition2 %rep = 1445/1460, RoofMatl %rep = 1434/1460, \n",
    "# Heating %rep = 1428/1460, LowQualFinSF %rep = 1436/1460, \n",
    "# PoolArea %rep = 1454/1460, 3SsnPorch %rep = 1438/1460\n",
    "\n",
    "def deleteColumns(train, test):\n",
    "    columnsToDelete = ['Id','Utilities','Street','LandSlope', 'Condition2', 'RoofMatl',  'Heating', 'LowQualFinSF', 'PoolArea', '3SsnPorch']\n",
    "    train.drop(labels = columnsToDelete, axis = 1, inplace = True)\n",
    "    test.drop(labels = columnsToDelete, axis = 1, inplace = True)\n",
    "    \n",
    "deleteColumns(train, test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.2 Cuántas caracteristicas tiene el problema?: \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 2912 entries, 0 to 1451\n",
      "Data columns (total 204 columns):\n",
      " #   Column                 Dtype   \n",
      "---  ------                 -----   \n",
      " 0   LotFrontage            float64 \n",
      " 1   LotArea                int64   \n",
      " 2   OverallQual            int64   \n",
      " 3   OverallCond            int64   \n",
      " 4   YearBuilt              int64   \n",
      " 5   YearRemodAdd           int64   \n",
      " 6   MasVnrArea             float64 \n",
      " 7   ExterQual              int64   \n",
      " 8   ExterCond              int64   \n",
      " 9   BsmtQual               int64   \n",
      " 10  BsmtCond               int64   \n",
      " 11  BsmtExposure           int64   \n",
      " 12  BsmtFinSF1             float64 \n",
      " 13  BsmtFinSF2             float64 \n",
      " 14  BsmtUnfSF              float64 \n",
      " 15  TotalBsmtSF            float64 \n",
      " 16  HeatingQC              int64   \n",
      " 17  1stFlrSF               int64   \n",
      " 18  2ndFlrSF               int64   \n",
      " 19  GrLivArea              int64   \n",
      " 20  BsmtFullBath           float64 \n",
      " 21  BsmtHalfBath           float64 \n",
      " 22  FullBath               int64   \n",
      " 23  HalfBath               int64   \n",
      " 24  BedroomAbvGr           int64   \n",
      " 25  KitchenAbvGr           int64   \n",
      " 26  KitchenQual            int64   \n",
      " 27  TotRmsAbvGrd           int64   \n",
      " 28  Fireplaces             int64   \n",
      " 29  FireplaceQu            int64   \n",
      " 30  GarageYrBlt            float64 \n",
      " 31  GarageCars             float64 \n",
      " 32  GarageArea             float64 \n",
      " 33  GarageQual             int64   \n",
      " 34  GarageCond             int64   \n",
      " 35  WoodDeckSF             int64   \n",
      " 36  OpenPorchSF            int64   \n",
      " 37  EnclosedPorch          int64   \n",
      " 38  ScreenPorch            int64   \n",
      " 39  MiscVal                int64   \n",
      " 40  MoSold                 int64   \n",
      " 41  YrSold                 int64   \n",
      " 42  MSSubClass_30          uint8   \n",
      " 43  MSSubClass_40          uint8   \n",
      " 44  MSSubClass_45          uint8   \n",
      " 45  MSSubClass_50          uint8   \n",
      " 46  MSSubClass_60          uint8   \n",
      " 47  MSSubClass_70          uint8   \n",
      " 48  MSSubClass_75          uint8   \n",
      " 49  MSSubClass_80          uint8   \n",
      " 50  MSSubClass_85          uint8   \n",
      " 51  MSSubClass_90          uint8   \n",
      " 52  MSSubClass_120         uint8   \n",
      " 53  MSSubClass_150         uint8   \n",
      " 54  MSSubClass_160         uint8   \n",
      " 55  MSSubClass_180         uint8   \n",
      " 56  MSSubClass_190         uint8   \n",
      " 57  MSZoning_FV            uint8   \n",
      " 58  MSZoning_RH            uint8   \n",
      " 59  MSZoning_RL            uint8   \n",
      " 60  MSZoning_RM            uint8   \n",
      " 61  LotShape_IR2           uint8   \n",
      " 62  LotShape_IR3           uint8   \n",
      " 63  LotShape_Reg           uint8   \n",
      " 64  LandContour_HLS        uint8   \n",
      " 65  LandContour_Low        uint8   \n",
      " 66  LandContour_Lvl        uint8   \n",
      " 67  LotConfig_CulDSac      uint8   \n",
      " 68  LotConfig_FR2          uint8   \n",
      " 69  LotConfig_FR3          uint8   \n",
      " 70  LotConfig_Inside       uint8   \n",
      " 71  Neighborhood_Blueste   uint8   \n",
      " 72  Neighborhood_BrDale    uint8   \n",
      " 73  Neighborhood_BrkSide   uint8   \n",
      " 74  Neighborhood_ClearCr   uint8   \n",
      " 75  Neighborhood_CollgCr   uint8   \n",
      " 76  Neighborhood_Crawfor   uint8   \n",
      " 77  Neighborhood_Edwards   uint8   \n",
      " 78  Neighborhood_Gilbert   uint8   \n",
      " 79  Neighborhood_IDOTRR    uint8   \n",
      " 80  Neighborhood_MeadowV   uint8   \n",
      " 81  Neighborhood_Mitchel   uint8   \n",
      " 82  Neighborhood_NAmes     uint8   \n",
      " 83  Neighborhood_NPkVill   uint8   \n",
      " 84  Neighborhood_NWAmes    uint8   \n",
      " 85  Neighborhood_NoRidge   uint8   \n",
      " 86  Neighborhood_NridgHt   uint8   \n",
      " 87  Neighborhood_OldTown   uint8   \n",
      " 88  Neighborhood_SWISU     uint8   \n",
      " 89  Neighborhood_Sawyer    uint8   \n",
      " 90  Neighborhood_SawyerW   uint8   \n",
      " 91  Neighborhood_Somerst   uint8   \n",
      " 92  Neighborhood_StoneBr   uint8   \n",
      " 93  Neighborhood_Timber    uint8   \n",
      " 94  Neighborhood_Veenker   uint8   \n",
      " 95  Condition1_Feedr       uint8   \n",
      " 96  Condition1_Norm        uint8   \n",
      " 97  Condition1_PosA        uint8   \n",
      " 98  Condition1_PosN        uint8   \n",
      " 99  Condition1_RRAe        uint8   \n",
      " 100 Condition1_RRAn        uint8   \n",
      " 101 Condition1_RRNe        uint8   \n",
      " 102 Condition1_RRNn        uint8   \n",
      " 103 BldgType_2fmCon        uint8   \n",
      " 104 BldgType_Duplex        uint8   \n",
      " 105 BldgType_Twnhs         uint8   \n",
      " 106 BldgType_TwnhsE        uint8   \n",
      " 107 HouseStyle_1.5Unf      uint8   \n",
      " 108 HouseStyle_1Story      uint8   \n",
      " 109 HouseStyle_2.5Fin      uint8   \n",
      " 110 HouseStyle_2.5Unf      uint8   \n",
      " 111 HouseStyle_2Story      uint8   \n",
      " 112 HouseStyle_SFoyer      uint8   \n",
      " 113 HouseStyle_SLvl        uint8   \n",
      " 114 RoofStyle_Gable        uint8   \n",
      " 115 RoofStyle_Gambrel      uint8   \n",
      " 116 RoofStyle_Hip          uint8   \n",
      " 117 RoofStyle_Mansard      uint8   \n",
      " 118 RoofStyle_Shed         uint8   \n",
      " 119 Exterior1st_AsphShn    uint8   \n",
      " 120 Exterior1st_BrkComm    uint8   \n",
      " 121 Exterior1st_BrkFace    uint8   \n",
      " 122 Exterior1st_CBlock     uint8   \n",
      " 123 Exterior1st_CemntBd    uint8   \n",
      " 124 Exterior1st_HdBoard    uint8   \n",
      " 125 Exterior1st_ImStucc    uint8   \n",
      " 126 Exterior1st_MetalSd    uint8   \n",
      " 127 Exterior1st_Plywood    uint8   \n",
      " 128 Exterior1st_Stone      uint8   \n",
      " 129 Exterior1st_Stucco     uint8   \n",
      " 130 Exterior1st_VinylSd    uint8   \n",
      " 131 Exterior1st_Wd Sdng    uint8   \n",
      " 132 Exterior1st_WdShing    uint8   \n",
      " 133 Exterior2nd_AsphShn    uint8   \n",
      " 134 Exterior2nd_Brk Cmn    uint8   \n",
      " 135 Exterior2nd_BrkFace    uint8   \n",
      " 136 Exterior2nd_CBlock     uint8   \n",
      " 137 Exterior2nd_CmentBd    uint8   \n",
      " 138 Exterior2nd_HdBoard    uint8   \n",
      " 139 Exterior2nd_ImStucc    uint8   \n",
      " 140 Exterior2nd_MetalSd    uint8   \n",
      " 141 Exterior2nd_Other      uint8   \n",
      " 142 Exterior2nd_Plywood    uint8   \n",
      " 143 Exterior2nd_Stone      uint8   \n",
      " 144 Exterior2nd_Stucco     uint8   \n",
      " 145 Exterior2nd_VinylSd    uint8   \n",
      " 146 Exterior2nd_Wd Sdng    uint8   \n",
      " 147 Exterior2nd_Wd Shng    uint8   \n",
      " 148 MasVnrType_BrkFace     uint8   \n",
      " 149 MasVnrType_None        uint8   \n",
      " 150 MasVnrType_Stone       uint8   \n",
      " 151 Foundation_CBlock      uint8   \n",
      " 152 Foundation_PConc       uint8   \n",
      " 153 Foundation_Slab        uint8   \n",
      " 154 Foundation_Stone       uint8   \n",
      " 155 Foundation_Wood        uint8   \n",
      " 156 BsmtFinType1_BLQ       uint8   \n",
      " 157 BsmtFinType1_GLQ       uint8   \n",
      " 158 BsmtFinType1_LwQ       uint8   \n",
      " 159 BsmtFinType1_NA        uint8   \n",
      " 160 BsmtFinType1_Rec       uint8   \n",
      " 161 BsmtFinType1_Unf       uint8   \n",
      " 162 BsmtFinType2_BLQ       uint8   \n",
      " 163 BsmtFinType2_GLQ       uint8   \n",
      " 164 BsmtFinType2_LwQ       uint8   \n",
      " 165 BsmtFinType2_NA        uint8   \n",
      " 166 BsmtFinType2_Rec       uint8   \n",
      " 167 BsmtFinType2_Unf       uint8   \n",
      " 168 CentralAir_Y           uint8   \n",
      " 169 Electrical_FuseF       uint8   \n",
      " 170 Electrical_FuseP       uint8   \n",
      " 171 Electrical_Mix         uint8   \n",
      " 172 Electrical_SBrkr       uint8   \n",
      " 173 Functional_Maj2        uint8   \n",
      " 174 Functional_Min1        uint8   \n",
      " 175 Functional_Min2        uint8   \n",
      " 176 Functional_Mod         uint8   \n",
      " 177 Functional_Sev         uint8   \n",
      " 178 Functional_Typ         uint8   \n",
      " 179 GarageType_Attchd      uint8   \n",
      " 180 GarageType_Basment     uint8   \n",
      " 181 GarageType_BuiltIn     uint8   \n",
      " 182 GarageType_CarPort     uint8   \n",
      " 183 GarageType_Detchd      uint8   \n",
      " 184 GarageType_NA          uint8   \n",
      " 185 GarageFinish_NA        uint8   \n",
      " 186 GarageFinish_RFn       uint8   \n",
      " 187 GarageFinish_Unf       uint8   \n",
      " 188 PavedDrive_P           uint8   \n",
      " 189 PavedDrive_Y           uint8   \n",
      " 190 SaleType_CWD           uint8   \n",
      " 191 SaleType_Con           uint8   \n",
      " 192 SaleType_ConLD         uint8   \n",
      " 193 SaleType_ConLI         uint8   \n",
      " 194 SaleType_ConLw         uint8   \n",
      " 195 SaleType_New           uint8   \n",
      " 196 SaleType_Oth           uint8   \n",
      " 197 SaleType_WD            uint8   \n",
      " 198 SaleCondition_AdjLand  uint8   \n",
      " 199 SaleCondition_Alloca   uint8   \n",
      " 200 SaleCondition_Family   uint8   \n",
      " 201 SaleCondition_Normal   uint8   \n",
      " 202 SaleCondition_Partial  uint8   \n",
      " 203 Set                    category\n",
      "dtypes: category(1), float64(11), int64(31), uint8(161)\n",
      "memory usage: 1.4 MB\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def mergeTrainAndTest(train, test):\n",
    "    trainToMerge = train.copy()\n",
    "    Ytrain = trainToMerge['SalePrice'] \n",
    "    trainToMerge.drop(labels = 'SalePrice', axis = 1, inplace = True)\n",
    "    trainToMerge['Set'] = 'train'\n",
    "    testToMerge = test.copy()\n",
    "    testToMerge['Set'] = 'test'\n",
    "    db = trainToMerge.copy()\n",
    "    db = db.append(testToMerge)\n",
    "    return db, Ytrain\n",
    "\n",
    "def convertToCategories(db):\n",
    "    db['MSSubClass'] = db['MSSubClass'].astype('category')\n",
    "    db[\"ExterQual\"] = db[\"ExterQual\"].map({'Ex': 5, 'Gd': 4, 'TA': 3, 'Fa': 2, 'Po': 1})\n",
    "    db[\"ExterCond\"] = db[\"ExterCond\"].map({'Ex': 5, 'Gd': 4, 'TA': 3, 'Fa': 2, 'Po': 1})\n",
    "    db[\"BsmtQual\"] = db[\"BsmtQual\"].map({'Ex': 5, 'Gd': 4, 'TA': 3, 'Fa': 2, 'Po': 1, 'NA': 0})\n",
    "    db[\"BsmtCond\"] = db[\"BsmtCond\"].map({'Ex': 5, 'Gd': 4, 'TA': 3, 'Fa': 2, 'Po': 1, 'NA': 0})\n",
    "    db[\"BsmtExposure\"] = db[\"BsmtExposure\"].map({'Gd': 4, 'Av': 3, 'Mn': 2, 'No': 1, 'NA': 0})\n",
    "    db[\"HeatingQC\"] = db[\"HeatingQC\"].map({'Ex': 5, 'Gd': 4, 'TA': 3, 'Fa': 2, 'Po': 1})\n",
    "    db[\"KitchenQual\"] = db[\"KitchenQual\"].map({'Ex': 5, 'Gd': 4, 'TA': 3, 'Fa': 2, 'Po': 1})\n",
    "    db[\"FireplaceQu\"] = db[\"FireplaceQu\"].map({'Ex': 5, 'Gd': 4, 'TA': 3, 'Fa': 2, 'Po': 1, 'NA': 0})\n",
    "    db[\"GarageQual\"] = db[\"GarageQual\"].map({'Ex': 5, 'Gd': 4, 'TA': 3, 'Fa': 2, 'Po': 1, 'NA': 0})\n",
    "    db[\"GarageCond\"] = db[\"GarageCond\"].map({'Ex': 5, 'Gd': 4, 'TA': 3, 'Fa': 2, 'Po': 1, 'NA': 0})\n",
    "    for i in db.select_dtypes(include='object').columns.to_list():\n",
    "        db[i] = db[i].astype('category')\n",
    "        \n",
    "def oneHotEncoding(db):\n",
    "    typeOfSet = db['Set']\n",
    "    db.drop(labels = 'Set', axis = 1, inplace = True)\n",
    "    featuresToEncode = db.select_dtypes(include='category').head().columns.values.tolist()\n",
    "    resultantDB = pd.get_dummies(db, columns = featuresToEncode, drop_first= True)\n",
    "    resultantDB = pd.concat([resultantDB, typeOfSet], axis=1)\n",
    "    return resultantDB\n",
    "\n",
    "db, Ytrain = mergeTrainAndTest(train, test)\n",
    "convertToCategories(db)\n",
    "\n",
    "db = oneHotEncoding(db)\n",
    "\n",
    "db.info(verbose=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X train obtenido\n",
      "(1460, 203)\n",
      "X test obtenido\n",
      "(1452, 203)\n",
      "Y train obtenido\n",
      "(1460,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jorge/anaconda3/lib/python3.7/site-packages/pandas/core/frame.py:3997: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  errors=errors,\n",
      "/home/jorge/anaconda3/lib/python3.7/site-packages/pandas/core/frame.py:3997: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  errors=errors,\n"
     ]
    }
   ],
   "source": [
    "def separateTestAndTrain(db):\n",
    "    \n",
    "    Xtrain = db.loc[db['Set'] == 'train']\n",
    "    Xtrain.drop(labels = 'Set', axis = 1, inplace = True)\n",
    "    Xtest = db.loc[db['Set'] == 'test']\n",
    "    Xtest.drop(labels = 'Set', axis = 1, inplace = True)\n",
    "    return Xtrain, Xtest\n",
    "\n",
    "Xtrain, Xtest = separateTestAndTrain(db)\n",
    "\n",
    "\n",
    "print(\"X train obtenido\")\n",
    "print(Xtrain.shape)\n",
    "\n",
    "print(\"X test obtenido\")\n",
    "print(Xtest.shape)\n",
    "\n",
    "print(\"Y train obtenido\")\n",
    "print(Ytrain.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Nota</b>: Agregue una celda en la cual incluya las líneas de código usadas para responder las preguntas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "\n",
    "#Separa conjunto de entrenamiento y validación del conjunto de test\n",
    "X_train_val, X_test, y_train_val, y_test = train_test_split(Xtrain, Ytrain, test_size=0.10, shuffle=True)\n",
    "\n",
    "#Separar entrenamiento del conjunto de validación\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train_val, y_train_val, test_size=0.20, shuffle=True)\n",
    "\n",
    "#SEGUNDO INTENTO\n",
    "\n",
    "#Separa conjunto de entrenamiento y test del de validación\n",
    "X_train, X_val, y_train, y_val = train_test_split(Xtrain, Ytrain, test_size=0.10, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# # GridSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_params(model, params, X_val, y_val):\n",
    "    estimator = ''\n",
    "    estimator = GridSearchCV(estimator = model, param_grid = params, cv = 3)\n",
    "    estimator.fit(X_val, y_val)\n",
    "    return estimator.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# # Medidas de error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import r2_score\n",
    "from math import sqrt\n",
    "#Medidas de error\n",
    "\n",
    "def mean_absolute_percentage_error(y_true, y_pred): \n",
    "    y_true, y_pred = np.array(y_true), np.array(y_pred)\n",
    "    return np.mean(np.abs((y_true - y_pred) / y_true)) * 100\n",
    "\n",
    "def errorMeasure(y_train, y_pred):\n",
    "    \n",
    "    rmse = sqrt(mean_squared_error(y_train, y_pred))\n",
    "    mae = mean_absolute_error(y_train, y_pred)\n",
    "    mape = mean_absolute_percentage_error(y_train, y_pred)\n",
    "    r2 = r2_score(y_train, y_pred)\n",
    "    \n",
    "    return {'rmse': rmse,'mae': mae, 'mape': mape, 'r2': r2}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_const_train, Y_const_train = Xtrain, Ytrain\n",
    "#Separa conjunto de entrenamiento y validación del conjunto de test\n",
    "X_train_val, X_test, y_train_val, y_test = train_test_split(Xtrain, Ytrain, test_size=0.10, shuffle=True)\n",
    "\n",
    "#Separar entrenamiento del conjunto de validación\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train_val, y_train_val, test_size=0.20, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import r2_score\n",
    "from math import sqrt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(234567)\n",
    "Folds = 4\n",
    "X_train_test, X_val, y_train_test, y_val = train_test_split(Xtrain, Ytrain, test_size=0.10, shuffle=True)\n",
    "\n",
    "n_estimators = [100,150, 200,300,400]\n",
    "max_features = ['auto']\n",
    "max_depth = [3,4]\n",
    "min_samples_split = [2, 0.1, 5, 10]\n",
    "criterion = [\"mse\", \"mae\"]\n",
    "\n",
    "randomForest_grid = {'n_estimators': n_estimators,\n",
    "                     'max_features': max_features,\n",
    "                     'max_depth': max_depth,\n",
    "                     'min_samples_split': min_samples_split,\n",
    "                     'criterion': criterion}\n",
    "\n",
    "params = get_params(RandomForestRegressor(), randomForest_grid, X_val, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'alpha': 100, 'fit_intercept': True, 'max_iter': 1000, 'normalize': True}"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paramsRandomForest = params\n",
    "paramsRandomForest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'n_estimators'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-204-fe8f5439cca3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     39\u001b[0m          + ', mape: '+ str(np.mean([error['mape'] for error in errorsVal])) + ', r2: '+ str(np.mean([error['r2'] for error in errorsVal])))\n\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m \u001b[0mramdonForest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-204-fe8f5439cca3>\u001b[0m in \u001b[0;36mramdonForest\u001b[0;34m(X_train_test, y_train_test)\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.60\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0mrf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m         rf = RandomForestRegressor(n_estimators =params['n_estimators'], max_features = params['max_features'], max_depth =\n\u001b[0m\u001b[1;32m     17\u001b[0m                                       params['max_depth'], min_samples_split= params['min_samples_split'])\n\u001b[1;32m     18\u001b[0m         \u001b[0mrf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'n_estimators'"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import StratifiedKFold, GridSearchCV\n",
    "from numpy import random\n",
    "import math\n",
    "\n",
    "def ramdonForest(X_train_test, y_train_test):\n",
    "    EficienciaTrain = np.zeros(Folds)\n",
    "    EficienciaVal = np.zeros(Folds)\n",
    "    errorsTrain = np.empty(Folds, dtype=object)\n",
    "    errorsVal = np.empty(Folds, dtype=object)\n",
    "    random.seed(234567)\n",
    "    \n",
    "    for i in range(0,4):\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X_train_test, y_train_test, test_size=0.60, shuffle=True)\n",
    "        rf = ''\n",
    "        rf = RandomForestRegressor(n_estimators =params['n_estimators'], max_features = params['max_features'], max_depth =\n",
    "                                      params['max_depth'], min_samples_split= params['min_samples_split'])\n",
    "        rf.fit(X_train, y_train)\n",
    "\n",
    "        #Validación con las muestras de entrenamiento\n",
    "        Ytrain_pred = rf.predict(X_train)\n",
    "\n",
    "        #Validación con las muestras de test\n",
    "        Yest = rf.predict(X_test)\n",
    "\n",
    "        #Evaluamos las predicciones del modelo con los datos de test\n",
    "        EficienciaTrain[i] = rf.score(X_train, y_train)\n",
    "        EficienciaVal[i] = rf.score(X_test, y_test)\n",
    "        errorsTrain[i] = errorMeasure(y_train, Ytrain_pred)\n",
    "        errorsVal[i] = errorMeasure(y_test, Yest)\n",
    "        i += 1\n",
    "\n",
    "    print('Eficiencia durante el entrenamiento = ' + str(np.mean(EficienciaTrain)) + '+-' + str(np.std(EficienciaTrain)))\n",
    "    print('Eficiencia durante la validación = ' + str(np.mean(EficienciaVal)) + '+-' + str(np.std(EficienciaVal)))\n",
    "\n",
    "    print('Errores train = rmse: '+ str(np.mean([error['rmse'] for error in errorsTrain])) + ', mae: ' + str(np.mean([error['mae'] for error in errorsTrain]))\n",
    "         + ', mape: '+ str(np.mean([error['mape'] for error in errorsTrain])) + ', r2: '+ str(np.mean([error['r2'] for error in errorsTrain])))\n",
    "    print('Errores test = rmse: '+ str(np.mean([error['rmse'] for error in errorsVal])) + ', mae: ' + str(np.mean([error['mae'] for error in errorsVal]))\n",
    "         + ', mape: '+ str(np.mean([error['mape'] for error in errorsVal])) + ', r2: '+ str(np.mean([error['r2'] for error in errorsVal])))\n",
    "\n",
    "ramdonForest(X_train_test, y_train_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'criterion': 'mse',\n",
       " 'max_depth': 4,\n",
       " 'max_features': 'auto',\n",
       " 'min_samples_split': 2,\n",
       " 'n_estimators': 100}"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Mejores hiperparametros obtenidos con conjunto de validación\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "n_estimators = [100,150, 200,300,400,500]\n",
    "max_features = ['auto', 'sqrt', 'log2']\n",
    "max_depth = [3,4]\n",
    "min_samples_split = [0.1]\n",
    "criterion = [\"mse\", \"mae\"]\n",
    "min_samples_split = [2,4,6,8,10,20]\n",
    "\n",
    "\n",
    "random_grid = {'n_estimators': n_estimators,\n",
    "               'max_features': max_features,\n",
    "               'max_depth': max_depth,\n",
    "               'min_samples_split': min_samples_split,\n",
    "               'criterion': criterion,\n",
    "               'min_samples_split' : min_samples_split}\n",
    "\n",
    "regr = RandomForestRegressor()\n",
    "regr_random = GridSearchCV(estimator = regr, param_grid = random_grid, cv = 3)\n",
    "regr_random.fit(X_val, y_val)\n",
    "\n",
    "regr_random.best_params_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Entramiento con metodología de validación usando los mejores hiperparametros, datos de entranmiento\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "import numpy as np\n",
    "\n",
    "regr = RandomForestRegressor(max_depth=4, random_state=0, n_estimators=150, min_samples_split=2, max_features='auto', criterion='mae')\n",
    "scores = cross_val_score(regr, X_train, y_train, cv=5, scoring='r2') #Score mse cross_val_predict\n",
    "\n",
    "print(scores)\n",
    "print('Intervalo de confianza',np.std(scores))\n",
    "print('Desempeño',np.mean(scores))\n",
    "                         "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Normalizar los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 100, 'epsilon': 0.1, 'gamma': 0.0001}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import StratifiedKFold, GridSearchCV\n",
    "from numpy import random\n",
    "import math\n",
    "from sklearn import linear_model\n",
    "\n",
    "\n",
    "random.seed(234567)\n",
    "Folds = 4\n",
    "X_train_test, X_val, y_train_test, y_val = train_test_split(Xtrain, Ytrain, test_size=0.10, shuffle=True)\n",
    "\n",
    "def paramsSVM(kernel):\n",
    "    random.seed(234567)\n",
    "    gamma = [0.0001,0.001, 0.01, 0.1, 1]\n",
    "    C = [1e4, 0.001, 0.01,0.1,1,10,100]\n",
    "    epsilon= [0.1, 1]\n",
    "\n",
    "    if (kernel == 'rbf'):\n",
    "        svr_grid = {'C': C,'epsilon': epsilon,'gamma' : gamma}        \n",
    "    else:\n",
    "        svr_grid = {'C': C,'epsilon': epsilon}\n",
    "\n",
    "    params = get_params(SVR(), svr_grid, X_val, y_val)\n",
    "    print(params)\n",
    "    return params\n",
    "    \n",
    "params = paramsSVM('rbf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 100, 'epsilon': 0.2, 'gamma': 0.001}"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "from sklearn.svm import SVR\n",
    "\n",
    "def modelSVM(kernel, X_train_test, y_train_test):\n",
    "    random.seed(234567)\n",
    "    params = paramsSVM(kernel)\n",
    "    EficienciaTrain = np.zeros(Folds)\n",
    "    EficienciaVal = np.zeros(Folds)\n",
    "    errorsTrain = np.empty(Folds, dtype=object)\n",
    "    errorsVal = np.empty(Folds, dtype=object)\n",
    "\n",
    "    for i in range(0,4):\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X_train_test, y_train_test, test_size=0.60, shuffle=True)\n",
    "        svr_freq = ''\n",
    "\n",
    "        scaler = preprocessing.StandardScaler().fit(X_train)\n",
    "        X_train = scaler.transform(X_train)\n",
    "        X_test = scaler.transform(X_test)\n",
    "\n",
    "        if(kernel == 'rbf'):\n",
    "            svr_rbf = SVR(C = params['C'], epsilon = params['epsilon'], gamma= params['gamma'], kernel='rbf')\n",
    "        else:\n",
    "            svr_rbf = SVR(C = params['C'], epsilon = params['epsilon'], kernel='linear')\n",
    "\n",
    "        svr_rbf.fit(X_train, y_train)\n",
    "\n",
    "        #Validación con las muestras de entrenamiento\n",
    "        Ytrain_pred = svr_rbf.predict(X_train)\n",
    "\n",
    "        #Validación con las muestras de test\n",
    "        Yest = svr_rbf.predict(X_test)\n",
    "\n",
    "        #Evaluamos las predicciones del modelo con los datos de test\n",
    "        EficienciaTrain[i] = svr_rbf.score(X_train, y_train)\n",
    "        EficienciaVal[i] = svr_rbf.score(X_test, y_test)\n",
    "        errorsTrain[i] = errorMeasure(y_train, Ytrain_pred)\n",
    "        errorsVal[i] = errorMeasure(y_test, Yest)\n",
    "        i += 1\n",
    "\n",
    "    print('Eficiencia durante el entrenamiento = ' + str(np.mean(EficienciaTrain)) + '+-' + str(np.std(EficienciaTrain)))\n",
    "    print('Eficiencia durante la validación = ' + str(np.mean(EficienciaVal)) + '+-' + str(np.std(EficienciaVal)))\n",
    "\n",
    "    print('Errores train = rmse: '+ str(np.mean([error['rmse'] for error in errorsTrain])) + ', mae: ' + str(np.mean([error['mae'] for error in errorsTrain]))\n",
    "         + ', mape: '+ str(np.mean([error['mape'] for error in errorsTrain])) + ', r2: '+ str(np.mean([error['r2'] for error in errorsTrain])))\n",
    "    print('Errores test = rmse: '+ str(np.mean([error['rmse'] for error in errorsVal])) + ', mae: ' + str(np.mean([error['mae'] for error in errorsVal]))\n",
    "         + ', mape: '+ str(np.mean([error['mape'] for error in errorsVal])) + ', r2: '+ str(np.mean([error['r2'] for error in errorsVal])))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVR - Kernel RBF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 100, 'epsilon': 0.1, 'gamma': 0.0001}\n",
      "Eficiencia durante el entrenamiento = -0.04947223888459945+-0.005622850694421614\n",
      "Eficiencia durante la validación = -0.05394473441116332+-0.00958734051094924\n",
      "Errores train = rmse: 82373.10292473949, mae: 55687.07942313616, mape: 31.662447320294394, r2: -0.04947223888459945\n",
      "Errores test = rmse: 80185.99258956217, mae: 54998.81619137284, mape: 30.890928084268687, r2: -0.05394473441116332\n"
     ]
    }
   ],
   "source": [
    "modelSVM('rbf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVR - Kernel Lineal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 100, 'epsilon': 0.2}\n",
      "Eficiencia durante el entrenamiento = 0.8207962212730869+-0.040145163576863166\n",
      "Eficiencia durante la validación = 0.8111656615435549+-0.021118860140128173\n",
      "Errores train = rmse: 32605.266767047327, mae: 14840.850185475612, mape: 7.774288379144431, r2: 0.820796221273087\n",
      "Errores test = rmse: 34802.71182550823, mae: 19210.092268210836, mape: 10.469222812784075, r2: 0.8111656615435549\n"
     ]
    }
   ],
   "source": [
    "modelSVM('linear')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Redes neuronales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(234567)\n",
    "Folds = 4\n",
    "X_train_test, X_val, y_train_test, y_val = train_test_split(Xtrain, Ytrain, test_size=0.10, shuffle=True)\n",
    "\n",
    "n_estimators = [100,150, 200,300,400]\n",
    "max_features = ['auto']\n",
    "max_depth = [3,4]\n",
    "min_samples_split = [2, 0.1, 5, 10]\n",
    "criterion = [\"mse\", \"mae\"]\n",
    "\n",
    "epochs=[10,20,30]\n",
    "batch_size = [10, 20, 40, 60, 80, 100]\n",
    "epochs = [10, 50, 100]\n",
    "\n",
    "# we choose the initializers that came at the top in our previous cross-validation!!\n",
    "init_mode = ['glorot_uniform', 'uniform'] \n",
    "batches = [128, 512]\n",
    "epochs = [10, 20]\n",
    "\n",
    "randomForest_grid = {'n_estimators': n_estimators,\n",
    "                     'max_features': max_features,\n",
    "                     'max_depth': max_depth,\n",
    "                     'min_samples_split': min_samples_split,\n",
    "                     'criterion': criterion}\n",
    "\n",
    "params = get_params(RandomForestRegressor(), randomForest_grid, X_val, y_val)\n",
    "\n",
    "# grid search for initializer, batch size and number of epochs\n",
    "param_grid = dict(epochs=epochs, batch_size=batches, init=init_mode)\n",
    "grid = GridSearchCV(estimator=model_init_batch_epoch_CV, \n",
    "                    param_grid=param_grid,\n",
    "                    cv=3)\n",
    "grid_result = grid.fit(x_train, y_train)\n",
    "\n",
    "\n",
    "# print results\n",
    "print(f'Best Accuracy for {grid_result.best_score_:.4} using {grid_result.best_params_}')\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(f'mean={mean:.4}, std={stdev:.4} using {param}')\n",
    "    \n",
    "    \n",
    "parameters = {'solver': ['lbfgs'], 'max_iter': [500,1000,1500], 'alpha': 10.0 ** -np.arange(1, 7), 'hidden_layer_sizes':np.arange(5, 12), 'random_state':[0,1,2,3,4,5,6,7,8,9]}\n",
    "clf_grid = GridSearchCV(neural_network.MLPClassifier(), parameters, n_jobs=-1)\n",
    "\n",
    "parameters = {'solver': ['lbfgs'], 'max_iter': [500,1000,1500], 'alpha': 10.0 ** -np.arange(1, 7), 'hidden_layer_sizes':np.arange(5, 12), 'random_state':[0,1,2,3,4,5,6,7,8,9]}\n",
    "clf_grid_hair_soul = GridSearchCV(neural_network.MLPClassifier(), parameters, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import StratifiedKFold, GridSearchCV\n",
    "from numpy import random\n",
    "import math\n",
    "\n",
    "\n",
    "EficienciaTrain = np.zeros(Folds)\n",
    "EficienciaVal = np.zeros(Folds)\n",
    "errorsTrain = np.empty(Folds, dtype=object)\n",
    "errorsVal = np.empty(Folds, dtype=object)\n",
    "\n",
    "for i in range(0,4):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_train_test, y_train_test, test_size=0.60, shuffle=True)\n",
    "    rf = ''\n",
    "    rf = RandomForestRegressor(n_estimators =params['n_estimators'], max_features = params['max_features'], max_depth =\n",
    "                                  params['max_depth'], min_samples_split= params['min_samples_split'])\n",
    "    rf.fit(X_train, y_train)\n",
    "    \n",
    "    #Validación con las muestras de entrenamiento\n",
    "    Ytrain_pred = rf.predict(X_train)\n",
    "\n",
    "    #Validación con las muestras de test\n",
    "    Yest = rf.predict(X_test)\n",
    "\n",
    "    #Evaluamos las predicciones del modelo con los datos de test\n",
    "    EficienciaTrain[i] = rf.score(X_train, y_train)\n",
    "    EficienciaVal[i] = rf.score(X_test, y_test)\n",
    "    errorsTrain[i] = errorMeasure(y_train, Ytrain_pred)\n",
    "    errorsVal[i] = errorMeasure(y_test, Yest)\n",
    "    i += 1\n",
    "    \n",
    "print('Eficiencia durante el entrenamiento = ' + str(np.mean(EficienciaTrain)) + '+-' + str(np.std(EficienciaTrain)))\n",
    "print('Eficiencia durante la validación = ' + str(np.mean(EficienciaVal)) + '+-' + str(np.std(EficienciaVal)))\n",
    "\n",
    "print('Errores train = rmse: '+ str(np.mean([error['rmse'] for error in errorsTrain])) + ', mae: ' + str(np.mean([error['mae'] for error in errorsTrain]))\n",
    "     + ', mape: '+ str(np.mean([error['mape'] for error in errorsTrain])) + ', r2: '+ str(np.mean([error['r2'] for error in errorsTrain])))\n",
    "print('Errores test = rmse: '+ str(np.mean([error['rmse'] for error in errorsVal])) + ', mae: ' + str(np.mean([error['mae'] for error in errorsVal]))\n",
    "     + ', mape: '+ str(np.mean([error['mape'] for error in errorsVal])) + ', r2: '+ str(np.mean([error['r2'] for error in errorsVal])))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature selection - Busqueda secuencial hacia adelante"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 562,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(2, 3, 4, 5, 11, 12, 18, 19, 20, 26, 28, 29, 30, 31)"
      ]
     },
     "execution_count": 562,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from mlxtend.feature_selection import SequentialFeatureSelector as SFS\n",
    "from mlxtend.plotting import plot_sequential_feature_selection as plot_sfs\n",
    "\n",
    "\n",
    "encoded = X_train.select_dtypes(include='uint8').head().columns.values.tolist()\n",
    "X_without_encoding = X_train.drop(columns= encoded)\n",
    "\n",
    "lr = RandomForestRegressor()\n",
    "\n",
    "sfs = SFS(lr, \n",
    "          k_features=(7,15), \n",
    "          forward=True, \n",
    "          floating=False, \n",
    "          scoring='neg_mean_squared_error',\n",
    "          cv=10)\n",
    "\n",
    "sfs = sfs.fit(X_without_encoding, y_train)\n",
    "fig = plot_sfs(sfs.get_metric_dict(), kind='std_err')\n",
    "\n",
    "plt.title('Sequential Forward Selection (w. StdErr)')\n",
    "plt.grid()\n",
    "plt.show()\n",
    "sfs.k_feature_idx_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(0, 1, 4, 7, 8, 11, 14, 18, 34, 55, 65, 79, 103, 137, 165)"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from mlxtend.feature_selection import SequentialFeatureSelector as SFS\n",
    "from mlxtend.plotting import plot_sequential_feature_selection as plot_sfs\n",
    "\n",
    "\n",
    "encoded = X_train.select_dtypes(include='uint8').head().columns.values.tolist()\n",
    "X_without_encoding = X_train.drop(columns= encoded)\n",
    "\n",
    "rf = RandomForestRegressor()\n",
    "\n",
    "sfs = SFS(lr, \n",
    "          k_features=(7,15), \n",
    "          forward=True, \n",
    "          floating=False, \n",
    "          scoring='neg_mean_squared_error',\n",
    "          cv=10)\n",
    "\n",
    "sfs = sfs.fit(X_train, y_train)\n",
    "fig = plot_sfs(sfs.get_metric_dict(), kind='std_err')\n",
    "\n",
    "plt.title('Sequential Forward Selection (w. StdErr)')\n",
    "plt.grid()\n",
    "plt.show()\n",
    "sfs.k_feature_idx_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LotArea</th>\n",
       "      <th>OverallQual</th>\n",
       "      <th>YearRemodAdd</th>\n",
       "      <th>1stFlrSF</th>\n",
       "      <th>2ndFlrSF</th>\n",
       "      <th>TotRmsAbvGrd</th>\n",
       "      <th>MSSubClass_30_caller</th>\n",
       "      <th>MSSubClass_60_caller</th>\n",
       "      <th>LotShape_IR3_caller</th>\n",
       "      <th>Neighborhood_NPkVill_caller</th>\n",
       "      <th>...</th>\n",
       "      <th>SaleType_ConLI_other</th>\n",
       "      <th>SaleType_ConLw</th>\n",
       "      <th>SaleType_New</th>\n",
       "      <th>SaleType_Oth</th>\n",
       "      <th>SaleType_WD</th>\n",
       "      <th>SaleCondition_AdjLand</th>\n",
       "      <th>SaleCondition_Alloca</th>\n",
       "      <th>SaleCondition_Family</th>\n",
       "      <th>SaleCondition_Normal</th>\n",
       "      <th>SaleCondition_Partial</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>334</th>\n",
       "      <td>9042</td>\n",
       "      <td>6</td>\n",
       "      <td>1998</td>\n",
       "      <td>943</td>\n",
       "      <td>695</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>293</th>\n",
       "      <td>16659</td>\n",
       "      <td>7</td>\n",
       "      <td>1994</td>\n",
       "      <td>1468</td>\n",
       "      <td>795</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1433</th>\n",
       "      <td>10261</td>\n",
       "      <td>6</td>\n",
       "      <td>2000</td>\n",
       "      <td>962</td>\n",
       "      <td>830</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>628</th>\n",
       "      <td>11606</td>\n",
       "      <td>5</td>\n",
       "      <td>1969</td>\n",
       "      <td>1040</td>\n",
       "      <td>1040</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>444</th>\n",
       "      <td>8750</td>\n",
       "      <td>7</td>\n",
       "      <td>1995</td>\n",
       "      <td>933</td>\n",
       "      <td>975</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1430</th>\n",
       "      <td>21930</td>\n",
       "      <td>5</td>\n",
       "      <td>2005</td>\n",
       "      <td>734</td>\n",
       "      <td>1104</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>266</th>\n",
       "      <td>11207</td>\n",
       "      <td>6</td>\n",
       "      <td>1997</td>\n",
       "      <td>802</td>\n",
       "      <td>709</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>818</th>\n",
       "      <td>8816</td>\n",
       "      <td>6</td>\n",
       "      <td>1971</td>\n",
       "      <td>1052</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>585</th>\n",
       "      <td>11443</td>\n",
       "      <td>8</td>\n",
       "      <td>2006</td>\n",
       "      <td>2028</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>353</th>\n",
       "      <td>8520</td>\n",
       "      <td>6</td>\n",
       "      <td>2003</td>\n",
       "      <td>720</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>525 rows × 176 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      LotArea  OverallQual  YearRemodAdd  1stFlrSF  2ndFlrSF  TotRmsAbvGrd  \\\n",
       "334      9042            6          1998       943       695             7   \n",
       "293     16659            7          1994      1468       795             9   \n",
       "1433    10261            6          2000       962       830             8   \n",
       "628     11606            5          1969      1040      1040             9   \n",
       "444      8750            7          1995       933       975             8   \n",
       "...       ...          ...           ...       ...       ...           ...   \n",
       "1430    21930            5          2005       734      1104             7   \n",
       "266     11207            6          1997       802       709             8   \n",
       "818      8816            6          1971      1052         0             6   \n",
       "585     11443            8          2006      2028         0             7   \n",
       "353      8520            6          2003       720         0             5   \n",
       "\n",
       "      MSSubClass_30_caller  MSSubClass_60_caller  LotShape_IR3_caller  \\\n",
       "334                      0                     1                    0   \n",
       "293                      0                     1                    0   \n",
       "1433                     0                     1                    0   \n",
       "628                      0                     1                    0   \n",
       "444                      0                     1                    0   \n",
       "...                    ...                   ...                  ...   \n",
       "1430                     0                     1                    1   \n",
       "266                      0                     1                    0   \n",
       "818                      0                     0                    0   \n",
       "585                      0                     0                    0   \n",
       "353                      1                     0                    0   \n",
       "\n",
       "      Neighborhood_NPkVill_caller  ...  SaleType_ConLI_other  SaleType_ConLw  \\\n",
       "334                             0  ...                     0               0   \n",
       "293                             0  ...                     0               0   \n",
       "1433                            0  ...                     0               0   \n",
       "628                             0  ...                     0               0   \n",
       "444                             0  ...                     0               0   \n",
       "...                           ...  ...                   ...             ...   \n",
       "1430                            0  ...                     0               0   \n",
       "266                             0  ...                     0               0   \n",
       "818                             0  ...                     0               0   \n",
       "585                             0  ...                     0               0   \n",
       "353                             0  ...                     0               0   \n",
       "\n",
       "      SaleType_New  SaleType_Oth  SaleType_WD  SaleCondition_AdjLand  \\\n",
       "334              0             0            1                      0   \n",
       "293              0             0            1                      0   \n",
       "1433             0             0            1                      0   \n",
       "628              0             0            1                      0   \n",
       "444              0             0            1                      0   \n",
       "...            ...           ...          ...                    ...   \n",
       "1430             0             0            1                      0   \n",
       "266              0             0            1                      0   \n",
       "818              0             0            1                      0   \n",
       "585              1             0            0                      0   \n",
       "353              0             0            1                      0   \n",
       "\n",
       "      SaleCondition_Alloca  SaleCondition_Family  SaleCondition_Normal  \\\n",
       "334                      0                     0                     1   \n",
       "293                      0                     0                     1   \n",
       "1433                     0                     0                     1   \n",
       "628                      0                     1                     0   \n",
       "444                      0                     0                     1   \n",
       "...                    ...                   ...                   ...   \n",
       "1430                     0                     0                     1   \n",
       "266                      0                     0                     1   \n",
       "818                      0                     0                     1   \n",
       "585                      0                     0                     0   \n",
       "353                      0                     0                     1   \n",
       "\n",
       "      SaleCondition_Partial  \n",
       "334                       0  \n",
       "293                       0  \n",
       "1433                      0  \n",
       "628                       0  \n",
       "444                       0  \n",
       "...                     ...  \n",
       "1430                      0  \n",
       "266                       0  \n",
       "818                       0  \n",
       "585                       1  \n",
       "353                       0  \n",
       "\n",
       "[525 rows x 176 columns]"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def selectNoCategorical(X_train):\n",
    "    indexFeature = sfs.k_feature_idx_\n",
    "    indexFeature = np.array(indexFeature)\n",
    "    #Selected features train\n",
    "    selectedFeacture = X_train[X_train.columns[indexFeature]]\n",
    "\n",
    "    encoded = X_train.select_dtypes(include='uint8').head().columns.values.tolist()\n",
    "    FeactureEncoded = X_train[encoded]\n",
    "\n",
    "    newX_train= selectedFeacture.join(FeactureEncoded, lsuffix='_caller', rsuffix='_other') \n",
    "    return newX_train\n",
    "\n",
    "    encoded = X_train.select_dtypes(include='uint8').head().columns.values.tolist()\n",
    "    X_without_encoding = X_train.drop(columns= encoded)\n",
    "\n",
    "newX_train = selectNoCategorical(X_train)\n",
    "newX_train\n",
    "\n",
    "def selectNoCategoricalIndex(X_train, index):\n",
    "    indexFeature = index\n",
    "    indexFeature = np.array(indexFeature)\n",
    "    #Selected features train\n",
    "    selectedFeacture = X_train[X_train.columns[indexFeature]]\n",
    "\n",
    "    encoded = X_train.select_dtypes(include='uint8').head().columns.values.tolist()\n",
    "    FeactureEncoded = X_train[encoded]\n",
    "\n",
    "    newX_train= selectedFeacture.join(FeactureEncoded, lsuffix='_caller', rsuffix='_other') \n",
    "    return newX_train\n",
    "\n",
    "    encoded = X_train.select_dtypes(include='uint8').head().columns.values.tolist()\n",
    "    X_without_encoding = X_train.drop(columns= encoded)\n",
    "\n",
    "newX_train = selectNoCategorical(X_train)\n",
    "newX_train\n",
    "\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 1, 4, 7, 8, 11, 14, 18, 34, 55, 65, 79, 103, 137, 165)"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sfs.k_feature_idx_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eficiencia durante el entrenamiento = 0.9018889357405178+-0.008777028347185158\n",
      "Eficiencia durante la validación = 0.7744655959460225+-0.03420636462442766\n",
      "Errores train = rmse: 25115.777444417083, mae: 18249.276165958276, mape: 11.631446523439587, r2: 0.9018889357405179\n",
      "Errores test = rmse: 36993.73443059386, mae: 22959.40458078998, mape: 13.94494717312586, r2: 0.7744655959460225\n",
      "Eficiencia durante el entrenamiento = 0.9062446255733257+-0.007125325030473708\n",
      "Eficiencia durante la validación = 0.7777529102739413+-0.028727934778000994\n",
      "Errores train = rmse: 24563.83551434306, mae: 17728.49983031569, mape: 11.361077666727972, r2: 0.9062446255733257\n",
      "Errores test = rmse: 36764.908837081006, mae: 22684.080430437592, mape: 13.766103293445813, r2: 0.7777529102739413\n"
     ]
    }
   ],
   "source": [
    "#Prueba con arboles\n",
    "\n",
    "#Entramiento con metodología de validación usando los mejores hiperparametros, datos de entranmiento\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "import numpy as np\n",
    "\n",
    "selectCaract = selectNoCategorical(X_train_test)\n",
    "ramdonForest(selectCaract, y_train_test)\n",
    "ramdonForest(X_train_test, y_train_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'n_estimators'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-206-55426fa0511b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mselectCaract\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mselectNoCategorical\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mramdonForest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mselectCaract\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0mramdonForest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-204-fe8f5439cca3>\u001b[0m in \u001b[0;36mramdonForest\u001b[0;34m(X_train_test, y_train_test)\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.60\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0mrf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m         rf = RandomForestRegressor(n_estimators =params['n_estimators'], max_features = params['max_features'], max_depth =\n\u001b[0m\u001b[1;32m     17\u001b[0m                                       params['max_depth'], min_samples_split= params['min_samples_split'])\n\u001b[1;32m     18\u001b[0m         \u001b[0mrf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'n_estimators'"
     ]
    }
   ],
   "source": [
    "#Prueba con arboles - todas las caracteristicas\n",
    "\n",
    "selectCaract\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "import numpy as np\n",
    "\n",
    "selectCaract = selectNoCategorical(X_train_test)\n",
    "ramdonForest(selectCaract, y_train_test)\n",
    "ramdonForest(X_train_test, y_train_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 10000.0, 'epsilon': 1}\n",
      "Eficiencia durante el entrenamiento = 0.8235977973823778+-0.025022189116968657\n",
      "Eficiencia durante la validación = 0.7084776311405476+-0.011183187696432263\n",
      "Errores train = rmse: 32785.70428871197, mae: 17839.281582165844, mape: 9.418526278535364, r2: 0.8235977973823777\n",
      "Errores test = rmse: 42994.626139377826, mae: 28631.430896314458, mape: 16.714358873171214, r2: 0.7084776311405476\n"
     ]
    }
   ],
   "source": [
    "#SVR - Linear con nuevas caracteristicas\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "import numpy as np\n",
    "\n",
    "selectCaract = selectNoCategorical(X_train_test)\n",
    "modelSVM('linear', selectCaract, y_train_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SVR - RBF con nuevas caracteristicas\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "import numpy as np\n",
    "\n",
    "selectCaract = selectNoCategorical(X_train_test)\n",
    "modelSVR('rbf', selectCaract, y_train_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jorge/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 5562706544.092499, tolerance: 362044673.5007\n",
      "  positive)\n",
      "/home/jorge/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 9360810226.978764, tolerance: 382873895.0\n",
      "  positive)\n",
      "/home/jorge/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 7912908516.192999, tolerance: 373223084.0007\n",
      "  positive)\n",
      "/home/jorge/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 5562706544.092499, tolerance: 362044673.5007\n",
      "  positive)\n",
      "/home/jorge/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 9360810226.978764, tolerance: 382873895.0\n",
      "  positive)\n",
      "/home/jorge/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 7912908516.192999, tolerance: 373223084.0007\n",
      "  positive)\n",
      "/home/jorge/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1108446482.4620872, tolerance: 382873895.0\n",
      "  positive)\n",
      "/home/jorge/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1108446482.4620872, tolerance: 382873895.0\n",
      "  positive)\n",
      "/home/jorge/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1130012330.8966103, tolerance: 60770253.66885567\n",
      "  positive)\n",
      "/home/jorge/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1324503361.1713238, tolerance: 57701111.49484536\n",
      "  positive)\n",
      "/home/jorge/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1309918691.5099504, tolerance: 77234140.09469083\n",
      "  positive)\n",
      "/home/jorge/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1162682741.369665, tolerance: 60770253.66885567\n",
      "  positive)\n",
      "/home/jorge/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1354853775.047527, tolerance: 57701111.49484536\n",
      "  positive)\n",
      "/home/jorge/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1347781292.4582922, tolerance: 77234140.09469083\n",
      "  positive)\n",
      "/home/jorge/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 87228825.57831377, tolerance: 60770253.66885567\n",
      "  positive)\n",
      "/home/jorge/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 84986700.70623633, tolerance: 57701111.49484536\n",
      "  positive)\n",
      "/home/jorge/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 88229649.84086071, tolerance: 77234140.09469083\n",
      "  positive)\n",
      "/home/jorge/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 5876476790.169754, tolerance: 362044673.5007\n",
      "  positive)\n",
      "/home/jorge/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 9650110000.304808, tolerance: 382873895.0\n",
      "  positive)\n",
      "/home/jorge/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 8198982628.517918, tolerance: 373223084.0007\n",
      "  positive)\n",
      "/home/jorge/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 5876476790.169754, tolerance: 362044673.5007\n",
      "  positive)\n",
      "/home/jorge/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 9650110000.304808, tolerance: 382873895.0\n",
      "  positive)\n",
      "/home/jorge/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 8198982628.517918, tolerance: 373223084.0007\n",
      "  positive)\n",
      "/home/jorge/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 675801702.0443792, tolerance: 362044673.5007\n",
      "  positive)\n",
      "/home/jorge/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1469704157.888462, tolerance: 382873895.0\n",
      "  positive)\n",
      "/home/jorge/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 629480573.1977239, tolerance: 373223084.0007\n",
      "  positive)\n",
      "/home/jorge/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 675801702.0443792, tolerance: 362044673.5007\n",
      "  positive)\n",
      "/home/jorge/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1469704157.888462, tolerance: 382873895.0\n",
      "  positive)\n",
      "/home/jorge/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 629480573.1977239, tolerance: 373223084.0007\n",
      "  positive)\n",
      "/home/jorge/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1338245329.0298781, tolerance: 60770253.66885567\n",
      "  positive)\n",
      "/home/jorge/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1472266029.4977152, tolerance: 57701111.49484536\n",
      "  positive)\n",
      "/home/jorge/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1497463792.3528783, tolerance: 77234140.09469083\n",
      "  positive)\n",
      "/home/jorge/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1658578443.5857491, tolerance: 60770253.66885567\n",
      "  positive)\n",
      "/home/jorge/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1766368163.8843637, tolerance: 57701111.49484536\n",
      "  positive)\n",
      "/home/jorge/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1867908897.5652494, tolerance: 77234140.09469083\n",
      "  positive)\n",
      "/home/jorge/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 257757821.22422913, tolerance: 60770253.66885567\n",
      "  positive)\n",
      "/home/jorge/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 224415148.1582121, tolerance: 57701111.49484536\n",
      "  positive)\n",
      "/home/jorge/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 257618744.16916853, tolerance: 77234140.09469083\n",
      "  positive)\n",
      "/home/jorge/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 594927193.0157703, tolerance: 60770253.66885567\n",
      "  positive)\n",
      "/home/jorge/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 511784724.2403726, tolerance: 57701111.49484536\n",
      "  positive)\n",
      "/home/jorge/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 595426484.4223337, tolerance: 77234140.09469083\n",
      "  positive)\n",
      "/home/jorge/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 177167641.08409163, tolerance: 60770253.66885567\n",
      "  positive)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jorge/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 166801190.511502, tolerance: 57701111.49484536\n",
      "  positive)\n",
      "/home/jorge/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 168220517.51590133, tolerance: 77234140.09469083\n",
      "  positive)\n",
      "/home/jorge/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 294269078.18485886, tolerance: 60770253.66885567\n",
      "  positive)\n",
      "/home/jorge/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 175598007.7946983, tolerance: 57701111.49484536\n",
      "  positive)\n",
      "/home/jorge/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 327741839.8530914, tolerance: 77234140.09469083\n",
      "  positive)\n",
      "/home/jorge/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 130113025.74117377, tolerance: 60770253.66885567\n",
      "  positive)\n",
      "/home/jorge/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 128048190.57785806, tolerance: 57701111.49484536\n",
      "  positive)\n",
      "/home/jorge/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 124990010.77627598, tolerance: 77234140.09469083\n",
      "  positive)\n",
      "/home/jorge/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 8858564973.99265, tolerance: 362044673.5007\n",
      "  positive)\n",
      "/home/jorge/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 12420746511.089735, tolerance: 382873895.0\n",
      "  positive)\n",
      "/home/jorge/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 10911786096.717995, tolerance: 373223084.0007\n",
      "  positive)\n",
      "/home/jorge/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 8858564973.99265, tolerance: 362044673.5007\n",
      "  positive)\n",
      "/home/jorge/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 12420746511.089735, tolerance: 382873895.0\n",
      "  positive)\n",
      "/home/jorge/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 10911786096.717995, tolerance: 373223084.0007\n",
      "  positive)\n",
      "/home/jorge/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 3276389563.82202, tolerance: 362044673.5007\n",
      "  positive)\n",
      "/home/jorge/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 4417218998.321482, tolerance: 382873895.0\n",
      "  positive)\n",
      "/home/jorge/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 3495153642.8260884, tolerance: 373223084.0007\n",
      "  positive)\n",
      "/home/jorge/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 3276389563.82202, tolerance: 362044673.5007\n",
      "  positive)\n",
      "/home/jorge/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 4417218998.321482, tolerance: 382873895.0\n",
      "  positive)\n",
      "/home/jorge/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 3495153642.8260884, tolerance: 373223084.0007\n",
      "  positive)\n",
      "/home/jorge/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1838960333.2825403, tolerance: 362044673.5007\n",
      "  positive)\n",
      "/home/jorge/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1647861926.775931, tolerance: 382873895.0\n",
      "  positive)\n",
      "/home/jorge/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1691499547.694462, tolerance: 373223084.0007\n",
      "  positive)\n",
      "/home/jorge/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1838960333.2825403, tolerance: 362044673.5007\n",
      "  positive)\n",
      "/home/jorge/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1647861926.775931, tolerance: 382873895.0\n",
      "  positive)\n",
      "/home/jorge/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1691499547.694462, tolerance: 373223084.0007\n",
      "  positive)\n",
      "/home/jorge/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1335662758.346851, tolerance: 362044673.5007\n",
      "  positive)\n",
      "/home/jorge/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1200586882.518564, tolerance: 382873895.0\n",
      "  positive)\n",
      "/home/jorge/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1244654355.3354487, tolerance: 373223084.0007\n",
      "  positive)\n",
      "/home/jorge/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1335662758.346851, tolerance: 362044673.5007\n",
      "  positive)\n",
      "/home/jorge/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1200586882.518564, tolerance: 382873895.0\n",
      "  positive)\n",
      "/home/jorge/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1244654355.3354487, tolerance: 373223084.0007\n",
      "  positive)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jorge/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 3237116126.288148, tolerance: 60770253.66885567\n",
      "  positive)\n",
      "/home/jorge/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 2812801546.8945036, tolerance: 57701111.49484536\n",
      "  positive)\n",
      "/home/jorge/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 3185153011.4537454, tolerance: 77234140.09469083\n",
      "  positive)\n",
      "/home/jorge/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 5952826713.822247, tolerance: 60770253.66885567\n",
      "  positive)\n",
      "/home/jorge/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 5012827991.433221, tolerance: 57701111.49484536\n",
      "  positive)\n",
      "/home/jorge/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 6190738153.348059, tolerance: 77234140.09469083\n",
      "  positive)\n",
      "/home/jorge/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1738822900.739963, tolerance: 60770253.66885567\n",
      "  positive)\n",
      "/home/jorge/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1533396692.5186958, tolerance: 57701111.49484536\n",
      "  positive)\n",
      "/home/jorge/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1617522026.6278906, tolerance: 77234140.09469083\n",
      "  positive)\n",
      "/home/jorge/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 2430329341.931037, tolerance: 60770253.66885567\n",
      "  positive)\n",
      "/home/jorge/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 2221522097.895133, tolerance: 57701111.49484536\n",
      "  positive)\n",
      "/home/jorge/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 2447680913.0169187, tolerance: 77234140.09469083\n",
      "  positive)\n",
      "/home/jorge/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1228260400.845989, tolerance: 60770253.66885567\n",
      "  positive)\n",
      "/home/jorge/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1092333164.8470771, tolerance: 57701111.49484536\n",
      "  positive)\n",
      "/home/jorge/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1185711360.2865984, tolerance: 77234140.09469083\n",
      "  positive)\n",
      "/home/jorge/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1161175521.0125356, tolerance: 60770253.66885567\n",
      "  positive)\n",
      "/home/jorge/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1029699968.4030179, tolerance: 57701111.49484536\n",
      "  positive)\n",
      "/home/jorge/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1098633308.4933898, tolerance: 77234140.09469083\n",
      "  positive)\n",
      "/home/jorge/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 29086947883.9088, tolerance: 362044673.5007\n",
      "  positive)\n",
      "/home/jorge/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 32121845439.809006, tolerance: 382873895.0\n",
      "  positive)\n",
      "/home/jorge/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 28850605087.96432, tolerance: 373223084.0007\n",
      "  positive)\n",
      "/home/jorge/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 29086947883.9088, tolerance: 362044673.5007\n",
      "  positive)\n",
      "/home/jorge/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 32121845439.809006, tolerance: 382873895.0\n",
      "  positive)\n",
      "/home/jorge/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 28850605087.96432, tolerance: 373223084.0007\n",
      "  positive)\n",
      "/home/jorge/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 13865305174.716934, tolerance: 362044673.5007\n",
      "  positive)\n",
      "/home/jorge/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 13118946735.669075, tolerance: 382873895.0\n",
      "  positive)\n",
      "/home/jorge/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 12430328508.774632, tolerance: 373223084.0007\n",
      "  positive)\n",
      "/home/jorge/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 13865305174.716934, tolerance: 362044673.5007\n",
      "  positive)\n",
      "/home/jorge/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 13118946735.669075, tolerance: 382873895.0\n",
      "  positive)\n",
      "/home/jorge/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 12430328508.774632, tolerance: 373223084.0007\n",
      "  positive)\n",
      "/home/jorge/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 9624402279.405243, tolerance: 362044673.5007\n",
      "  positive)\n",
      "/home/jorge/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 8031460656.288361, tolerance: 382873895.0\n",
      "  positive)\n",
      "/home/jorge/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 9431803018.850756, tolerance: 373223084.0007\n",
      "  positive)\n",
      "/home/jorge/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 9624402279.405243, tolerance: 362044673.5007\n",
      "  positive)\n",
      "/home/jorge/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 8031460656.288361, tolerance: 382873895.0\n",
      "  positive)\n",
      "/home/jorge/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 9431803018.850756, tolerance: 373223084.0007\n",
      "  positive)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jorge/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 8638462210.301308, tolerance: 362044673.5007\n",
      "  positive)\n",
      "/home/jorge/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 6953482874.1697, tolerance: 382873895.0\n",
      "  positive)\n",
      "/home/jorge/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 8015402268.428393, tolerance: 373223084.0007\n",
      "  positive)\n",
      "/home/jorge/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 8638462210.301308, tolerance: 362044673.5007\n",
      "  positive)\n",
      "/home/jorge/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 6953482874.1697, tolerance: 382873895.0\n",
      "  positive)\n",
      "/home/jorge/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 8015402268.428393, tolerance: 373223084.0007\n",
      "  positive)\n",
      "/home/jorge/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 14469364567.764364, tolerance: 60770253.66885567\n",
      "  positive)\n",
      "/home/jorge/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 10672844891.540127, tolerance: 57701111.49484536\n",
      "  positive)\n",
      "/home/jorge/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 13170084480.443737, tolerance: 77234140.09469083\n",
      "  positive)\n",
      "/home/jorge/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 18578065014.707138, tolerance: 60770253.66885567\n",
      "  positive)\n",
      "/home/jorge/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 15537828034.253448, tolerance: 57701111.49484536\n",
      "  positive)\n",
      "/home/jorge/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 23154895208.51904, tolerance: 77234140.09469083\n",
      "  positive)\n",
      "/home/jorge/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 9190837987.878712, tolerance: 60770253.66885567\n",
      "  positive)\n",
      "/home/jorge/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 7068131874.136522, tolerance: 57701111.49484536\n",
      "  positive)\n",
      "/home/jorge/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 9100361304.105925, tolerance: 77234140.09469083\n",
      "  positive)\n",
      "/home/jorge/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 63868980.151405334, tolerance: 60770253.66885567\n",
      "  positive)\n",
      "/home/jorge/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 791537561.0827494, tolerance: 77234140.09469083\n",
      "  positive)\n",
      "/home/jorge/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 3427609458.350763, tolerance: 60770253.66885567\n",
      "  positive)\n",
      "/home/jorge/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 6259083733.355282, tolerance: 57701111.49484536\n",
      "  positive)\n",
      "/home/jorge/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 7992292589.2494545, tolerance: 77234140.09469083\n",
      "  positive)\n",
      "/home/jorge/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 85885868519.03104, tolerance: 362044673.5007\n",
      "  positive)\n",
      "/home/jorge/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 74236050860.25967, tolerance: 382873895.0\n",
      "  positive)\n",
      "/home/jorge/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 77578725741.45398, tolerance: 373223084.0007\n",
      "  positive)\n",
      "/home/jorge/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 85885868519.03104, tolerance: 362044673.5007\n",
      "  positive)\n",
      "/home/jorge/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 74236050860.25967, tolerance: 382873895.0\n",
      "  positive)\n",
      "/home/jorge/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 77578725741.45398, tolerance: 373223084.0007\n",
      "  positive)\n",
      "/home/jorge/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 44639127668.72255, tolerance: 362044673.5007\n",
      "  positive)\n",
      "/home/jorge/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 27081346157.864265, tolerance: 382873895.0\n",
      "  positive)\n",
      "/home/jorge/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43186337271.03119, tolerance: 373223084.0007\n",
      "  positive)\n",
      "/home/jorge/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 44639127668.72255, tolerance: 362044673.5007\n",
      "  positive)\n",
      "/home/jorge/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 27081346157.864265, tolerance: 382873895.0\n",
      "  positive)\n",
      "/home/jorge/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43186337271.03119, tolerance: 373223084.0007\n",
      "  positive)\n",
      "/home/jorge/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 35980684649.05583, tolerance: 362044673.5007\n",
      "  positive)\n",
      "/home/jorge/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 21768461596.108604, tolerance: 382873895.0\n",
      "  positive)\n",
      "/home/jorge/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 33749417615.584877, tolerance: 373223084.0007\n",
      "  positive)\n",
      "/home/jorge/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 35980684649.05583, tolerance: 362044673.5007\n",
      "  positive)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jorge/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 21768461596.108604, tolerance: 382873895.0\n",
      "  positive)\n",
      "/home/jorge/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 33749417615.584877, tolerance: 373223084.0007\n",
      "  positive)\n",
      "/home/jorge/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 34566534615.03784, tolerance: 362044673.5007\n",
      "  positive)\n",
      "/home/jorge/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 19915866356.336422, tolerance: 382873895.0\n",
      "  positive)\n",
      "/home/jorge/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 30655855364.285545, tolerance: 373223084.0007\n",
      "  positive)\n",
      "/home/jorge/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 34566534615.03784, tolerance: 362044673.5007\n",
      "  positive)\n",
      "/home/jorge/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 19915866356.336422, tolerance: 382873895.0\n",
      "  positive)\n",
      "/home/jorge/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 30655855364.285545, tolerance: 373223084.0007\n",
      "  positive)\n",
      "/home/jorge/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 38806183044.12862, tolerance: 60770253.66885567\n",
      "  positive)\n",
      "/home/jorge/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 23420360266.192947, tolerance: 57701111.49484536\n",
      "  positive)\n",
      "/home/jorge/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 38888562346.32184, tolerance: 77234140.09469083\n",
      "  positive)\n",
      "/home/jorge/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 4201109840.8741913, tolerance: 60770253.66885567\n",
      "  positive)\n",
      "/home/jorge/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 2664280252.256653, tolerance: 57701111.49484536\n",
      "  positive)\n",
      "/home/jorge/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 8132337255.14418, tolerance: 77234140.09469083\n",
      "  positive)\n",
      "/home/jorge/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 29004127936.84742, tolerance: 60770253.66885567\n",
      "  positive)\n",
      "/home/jorge/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 17639457712.017212, tolerance: 57701111.49484536\n",
      "  positive)\n",
      "/home/jorge/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 30624455118.455555, tolerance: 77234140.09469083\n",
      "  positive)\n",
      "/home/jorge/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 262842913.1448822, tolerance: 60770253.66885567\n",
      "  positive)\n",
      "/home/jorge/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 61908362.27903366, tolerance: 57701111.49484536\n",
      "  positive)\n",
      "/home/jorge/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 16833596747.013498, tolerance: 77234140.09469083\n",
      "  positive)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eficiencia durante el entrenamiento = 0.8497836661833259+-0.020683584065000524\n",
      "Eficiencia durante la validación = 0.7943999206599961+-0.02985690836243942\n",
      "Errores train = rmse: 32423.753174480087, mae: 20078.391431849872, mape: 11.785215304494537, r2: 0.8497836661833259\n",
      "Errores test = rmse: 34293.66425090245, mae: 20647.408229586006, mape: 12.471813037836128, r2: 0.7943999206599961\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import StratifiedKFold, GridSearchCV\n",
    "from numpy import random\n",
    "import math\n",
    "from sklearn import linear_model\n",
    "\n",
    "\n",
    "random.seed(234567)\n",
    "Folds = 4\n",
    "X_train_test, X_val, y_train_test, y_val = train_test_split(Xtrain, Ytrain, test_size=0.10, shuffle=True)\n",
    "\n",
    "alpha = [0.1, 1, 10, 100, 1000]\n",
    "fit_intercept=[False,True]\n",
    "normalize=[False,True]\n",
    "max_iter=[10, 100, 1000, 10000]\n",
    "\n",
    "regression_grid = {'alpha':alpha, 'fit_intercept':fit_intercept, 'normalize':normalize, 'max_iter':max_iter}\n",
    "params = get_params(linear_model.Lasso(), regression_grid, X_val, y_val)\n",
    "\n",
    "EficienciaTrain = np.zeros(Folds)\n",
    "EficienciaVal = np.zeros(Folds)\n",
    "errorsTrain = np.empty(Folds, dtype=object)\n",
    "errorsVal = np.empty(Folds, dtype=object)\n",
    "\n",
    "for i in range(0,4):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(selectCaract, y_train_test, test_size=0.60, shuffle=True)\n",
    "    regr_freq = ''\n",
    "    regr_freq = linear_model.Lasso(alpha =params['alpha'], fit_intercept = params['fit_intercept'], normalize =\n",
    "                                  params['normalize'], max_iter= params['max_iter'])\n",
    "    regr_freq.fit(X_train, y_train)\n",
    "    \n",
    "    #Validación con las muestras de entrenamiento\n",
    "    Ytrain_pred = regr_freq.predict(X_train)\n",
    "\n",
    "    #Validación con las muestras de test\n",
    "    Yest = regr_freq.predict(X_test)\n",
    "\n",
    "    #Evaluamos las predicciones del modelo con los datos de test\n",
    "    EficienciaTrain[i] = regr_freq.score(X_train, y_train)\n",
    "    EficienciaVal[i] = regr_freq.score(X_test, y_test)\n",
    "    errorsTrain[i] = errorMeasure(y_train, Ytrain_pred)\n",
    "    errorsVal[i] = errorMeasure(y_test, Yest)\n",
    "    i += 1\n",
    "    \n",
    "print('Eficiencia durante el entrenamiento = ' + str(np.mean(EficienciaTrain)) + '+-' + str(np.std(EficienciaTrain)))\n",
    "print('Eficiencia durante la validación = ' + str(np.mean(EficienciaVal)) + '+-' + str(np.std(EficienciaVal)))\n",
    "\n",
    "print('Errores train = rmse: '+ str(np.mean([error['rmse'] for error in errorsTrain])) + ', mae: ' + str(np.mean([error['mae'] for error in errorsTrain]))\n",
    "     + ', mape: '+ str(np.mean([error['mape'] for error in errorsTrain])) + ', r2: '+ str(np.mean([error['r2'] for error in errorsTrain])))\n",
    "print('Errores test = rmse: '+ str(np.mean([error['rmse'] for error in errorsVal])) + ', mae: ' + str(np.mean([error['mae'] for error in errorsVal]))\n",
    "     + ', mape: '+ str(np.mean([error['mape'] for error in errorsVal])) + ', r2: '+ str(np.mean([error['r2'] for error in errorsVal])))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 585,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Desempeño 0.4343829330683867\n",
      "Accuracy: 0.81 (+/- 0.05)\n"
     ]
    }
   ],
   "source": [
    "#Prueba con SVR Lineal\n",
    "\n",
    "#Desempeño con el conjunto test - Selección forward\n",
    "\n",
    "kernel, X_train_test, y_train_test\n",
    "\n",
    "params = KernelLineal\n",
    "clf = SVR(C = params['C'], epsilon = params['epsilon'], gamma =params['gamma'], kernel = 'linear').fit(newX_train, y_train)\n",
    "desempeño = clf.score(newX_test, y_test)     \n",
    "print('Desempeño', desempeño)\n",
    "print(\"Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature selection - Busqueda secuencial hacia atras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Selection Backward\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from mlxtend.feature_selection import SequentialFeatureSelector as SFS\n",
    "from mlxtend.plotting import plot_sequential_feature_selection as plot_sfs\n",
    "\n",
    "encoded = Xtrain.select_dtypes(include='uint8').head().columns.values.tolist()\n",
    "X_without_encoding = Xtrain.drop(columns= encoded)\n",
    "lr = RandomForestRegressor()\n",
    "\n",
    "sfs = SFS(lr, \n",
    "          k_features=(1,39), \n",
    "          forward=False, \n",
    "          floating=False, \n",
    "          scoring='neg_mean_squared_error',\n",
    "          cv=10)\n",
    "\n",
    "sfs = sfs.fit(X_without_encoding, Ytrain)\n",
    "fig = plot_sfs(sfs.get_metric_dict(), kind='std_err')\n",
    "\n",
    "plt.title('Sequential Backward Selection (w. StdErr)')\n",
    "plt.grid()\n",
    "plt.show()\n",
    "sfs.k_feature_idx_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LotFrontage</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>OverallQual</th>\n",
       "      <th>OverallCond</th>\n",
       "      <th>YearBuilt</th>\n",
       "      <th>YearRemodAdd</th>\n",
       "      <th>MasVnrArea</th>\n",
       "      <th>ExterQual</th>\n",
       "      <th>ExterCond</th>\n",
       "      <th>BsmtQual</th>\n",
       "      <th>...</th>\n",
       "      <th>GarageArea</th>\n",
       "      <th>GarageQual</th>\n",
       "      <th>GarageCond</th>\n",
       "      <th>WoodDeckSF</th>\n",
       "      <th>OpenPorchSF</th>\n",
       "      <th>EnclosedPorch</th>\n",
       "      <th>ScreenPorch</th>\n",
       "      <th>MiscVal</th>\n",
       "      <th>MoSold</th>\n",
       "      <th>YrSold</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>65.0</td>\n",
       "      <td>8450</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>2003</td>\n",
       "      <td>2003</td>\n",
       "      <td>196.0</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>548.0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>61</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>80.0</td>\n",
       "      <td>9600</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>1976</td>\n",
       "      <td>1976</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>460.0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>298</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>68.0</td>\n",
       "      <td>11250</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>2001</td>\n",
       "      <td>2002</td>\n",
       "      <td>162.0</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>608.0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>42</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>2008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>60.0</td>\n",
       "      <td>9550</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>1915</td>\n",
       "      <td>1970</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>642.0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>35</td>\n",
       "      <td>272</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>84.0</td>\n",
       "      <td>14260</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>2000</td>\n",
       "      <td>2000</td>\n",
       "      <td>350.0</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>836.0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>192</td>\n",
       "      <td>84</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>2008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1455</th>\n",
       "      <td>62.0</td>\n",
       "      <td>7917</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>1999</td>\n",
       "      <td>2000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>460.0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>2007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1456</th>\n",
       "      <td>85.0</td>\n",
       "      <td>13175</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>1978</td>\n",
       "      <td>1988</td>\n",
       "      <td>119.0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>500.0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>349</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1457</th>\n",
       "      <td>66.0</td>\n",
       "      <td>9042</td>\n",
       "      <td>7</td>\n",
       "      <td>9</td>\n",
       "      <td>1941</td>\n",
       "      <td>2006</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>252.0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>60</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2500</td>\n",
       "      <td>5</td>\n",
       "      <td>2010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1458</th>\n",
       "      <td>68.0</td>\n",
       "      <td>9717</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>1950</td>\n",
       "      <td>1996</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>240.0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>366</td>\n",
       "      <td>0</td>\n",
       "      <td>112</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1459</th>\n",
       "      <td>75.0</td>\n",
       "      <td>9937</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>1965</td>\n",
       "      <td>1965</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>276.0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>736</td>\n",
       "      <td>68</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>2008</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1460 rows × 42 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      LotFrontage  LotArea  OverallQual  OverallCond  YearBuilt  YearRemodAdd  \\\n",
       "0            65.0     8450            7            5       2003          2003   \n",
       "1            80.0     9600            6            8       1976          1976   \n",
       "2            68.0    11250            7            5       2001          2002   \n",
       "3            60.0     9550            7            5       1915          1970   \n",
       "4            84.0    14260            8            5       2000          2000   \n",
       "...           ...      ...          ...          ...        ...           ...   \n",
       "1455         62.0     7917            6            5       1999          2000   \n",
       "1456         85.0    13175            6            6       1978          1988   \n",
       "1457         66.0     9042            7            9       1941          2006   \n",
       "1458         68.0     9717            5            6       1950          1996   \n",
       "1459         75.0     9937            5            6       1965          1965   \n",
       "\n",
       "      MasVnrArea  ExterQual  ExterCond  BsmtQual  ...  GarageArea  GarageQual  \\\n",
       "0          196.0          4          3         4  ...       548.0           3   \n",
       "1            0.0          3          3         4  ...       460.0           3   \n",
       "2          162.0          4          3         4  ...       608.0           3   \n",
       "3            0.0          3          3         3  ...       642.0           3   \n",
       "4          350.0          4          3         4  ...       836.0           3   \n",
       "...          ...        ...        ...       ...  ...         ...         ...   \n",
       "1455         0.0          3          3         4  ...       460.0           3   \n",
       "1456       119.0          3          3         4  ...       500.0           3   \n",
       "1457         0.0          5          4         3  ...       252.0           3   \n",
       "1458         0.0          3          3         3  ...       240.0           3   \n",
       "1459         0.0          4          3         3  ...       276.0           3   \n",
       "\n",
       "      GarageCond  WoodDeckSF  OpenPorchSF  EnclosedPorch  ScreenPorch  \\\n",
       "0              3           0           61              0            0   \n",
       "1              3         298            0              0            0   \n",
       "2              3           0           42              0            0   \n",
       "3              3           0           35            272            0   \n",
       "4              3         192           84              0            0   \n",
       "...          ...         ...          ...            ...          ...   \n",
       "1455           3           0           40              0            0   \n",
       "1456           3         349            0              0            0   \n",
       "1457           3           0           60              0            0   \n",
       "1458           3         366            0            112            0   \n",
       "1459           3         736           68              0            0   \n",
       "\n",
       "      MiscVal  MoSold  YrSold  \n",
       "0           0       2    2008  \n",
       "1           0       5    2007  \n",
       "2           0       9    2008  \n",
       "3           0       2    2006  \n",
       "4           0      12    2008  \n",
       "...       ...     ...     ...  \n",
       "1455        0       8    2007  \n",
       "1456        0       2    2010  \n",
       "1457     2500       5    2010  \n",
       "1458        0       4    2010  \n",
       "1459        0       6    2008  \n",
       "\n",
       "[1460 rows x 42 columns]"
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded = Xtrain.select_dtypes(include='uint8').head().columns.values.tolist()\n",
    "X_without_encoding = Xtrain.drop(columns= encoded)\n",
    "X_without_encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'n_estimators'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-215-726e6655b0ac>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mselectCaract\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mselectNoCategoricalIndex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0mramdonForest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mselectCaract\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0mramdonForest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-204-fe8f5439cca3>\u001b[0m in \u001b[0;36mramdonForest\u001b[0;34m(X_train_test, y_train_test)\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.60\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0mrf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m         rf = RandomForestRegressor(n_estimators =params['n_estimators'], max_features = params['max_features'], max_depth =\n\u001b[0m\u001b[1;32m     17\u001b[0m                                       params['max_depth'], min_samples_split= params['min_samples_split'])\n\u001b[1;32m     18\u001b[0m         \u001b[0mrf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'n_estimators'"
     ]
    }
   ],
   "source": [
    "#Prueba con arboles\n",
    "#(1, 2, 3, 4, 5, 11, 12, 17, 18, 19, 26, 27, 29, 32)\n",
    "index = [1, 2, 3, 4, 5, 11, 12, 17, 18, 19, 26, 27, 29, 32]\n",
    "\n",
    "#Entramiento con metodología de validación usando los mejores hiperparametros, datos de entranmiento\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "import numpy as np\n",
    "\n",
    "selectCaract = selectNoCategoricalIndex(X_train_test, index)\n",
    "ramdonForest(selectCaract, y_train_test)\n",
    "ramdonForest(X_train_test, y_train_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
