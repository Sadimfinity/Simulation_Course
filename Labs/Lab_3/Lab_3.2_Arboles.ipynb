{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Laboratorio 3 - Parte 2\n",
    "\n",
    "### Arboles de decisión y Random Forest\n",
    "\n",
    "### 2019-I\n",
    "\n",
    "#### Profesor: Julián D. Arias Londoño\n",
    "#### julian.ariasl@udea.edu.co\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Guía del laboratorio\n",
    "\n",
    "En esta archivo va a encontrar tanto celdas de código cómo celdas de texto con las instrucciones para desarrollar el laboratorio.\n",
    "\n",
    "Lea atentamente las instrucciones entregadas en las celdas de texto correspondientes y proceda con la solución de las preguntas planteadas.\n",
    "\n",
    "Nota: no olvide ir ejecutando las celdas de código de arriba hacia abajo para que no tenga errores de importación de librerías o por falta de definición de variables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Primer integrante:\n",
    "#### Segundo integrante:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import scipy as sc\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "# from __future__ import division\n",
    "\n",
    "#Algunas advertencias que queremos evitar\n",
    "import warnings\n",
    "warnings.filterwarnings(\"always\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio 1\n",
    "\n",
    "A continuación se leen los datos de un problema de clasificación. El problema corresponde a la clasifiación de dígitos escritos a mano, el cual fue abordado en el laboratorio anterior. Usaremos únicamente 4 de las 10 clases disponibles. Los datos fueron preprocesados para reducir el número de características. La técnica usada será analizada más adelante en el curso."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_digits\n",
    "from sklearn.decomposition import PCA\n",
    "digits = load_digits(n_class=4)\n",
    "\n",
    "#--------- preprocesamiento--------------------\n",
    "pca = PCA(0.99, whiten=True)\n",
    "data = pca.fit_transform(digits.data)\n",
    "\n",
    "#---------- Datos a usar ----------------------\n",
    "X = data\n",
    "Y = digits.target\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En la siguiente celda se define una simulación para entrenar y validar un modelo usando los datos previamente cargados. Complete el código para usar como modelo de predicción un arbol de decisión. Debe consultar todo lo relacionado con la creación, entrenamiento y uso en predicción de este modelo usando la librería scikit-learn. Consultar aquí: http://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html\n",
    "\n",
    "<b>Note</b> que existe una clase para modelos de clasificación y otra para modelos de regresión:\n",
    "http://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeRegressor.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eficiencia durante el entrenamiento = 1.0+-0.0\n",
      "Eficiencia durante la validación = 0.9041819614588368+-0.03325916115155368\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import numpy.matlib as matlib\n",
    "from numpy import random\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "from sklearn import tree\n",
    "\n",
    "\n",
    "\n",
    "#Validamos el modelo\n",
    "Folds = 4\n",
    "random.seed(19680801)\n",
    "EficienciaTrain = np.zeros(Folds)\n",
    "EficienciaVal = np.zeros(Folds)\n",
    "skf = StratifiedKFold(n_splits=Folds)\n",
    "j = 0\n",
    "for train, test in skf.split(X, Y):\n",
    "    Xtrain = X[train,:]\n",
    "    Ytrain = Y[train]\n",
    "    Xtest = X[test,:]\n",
    "    Ytest = Y[test]\n",
    "    \n",
    "    #Normalizamos los datos\n",
    "    #media = np.mean(Xtrain)\n",
    "    #desvia = np.std(Xtrain)\n",
    "    #Xtrain = sc.stats.stats.zscore(Xtrain)\n",
    "    #Xtest = (Xtest - np.matlib.repmat(media, Xtest.shape[0], 1))/matlib.repmat(desvia, Xtest.shape[0], 1)\n",
    "    \n",
    "    #Haga el llamado a la función para crear y entrenar el modelo usando los datos de entrenamiento\n",
    "    #model = ...\n",
    "    \n",
    "    #model = tree.DecisionTreeClassifier(criterion='entropy', max_depth=10)\n",
    "    model = tree.DecisionTreeClassifier(max_depth=10)\n",
    "    model.fit(Xtrain, Ytrain)\n",
    "    \n",
    "    \n",
    "    \n",
    "    #Validación\n",
    "    Ytrain_pred = model.predict(Xtrain) #Use el modelo previamente entrenado para hacer predicciones con las mismas muestras de entrenamiento\n",
    "    Yest = model.predict(Xtest) #Use el modelo previamente entrenado para hacer predicciones con las muestras de test\n",
    "    \n",
    "    #Evaluamos las predicciones del modelo con los datos de test\n",
    "    EficienciaTrain[j] = np.mean(Ytrain_pred.ravel() == Ytrain.ravel())\n",
    "    EficienciaVal[j] = np.mean(Yest.ravel() == Ytest.ravel())\n",
    "    j += 1\n",
    "        \n",
    "print('Eficiencia durante el entrenamiento = ' + str(np.mean(EficienciaTrain)) + '+-' + str(np.std(EficienciaTrain)))\n",
    "print('Eficiencia durante la validación = ' + str(np.mean(EficienciaVal)) + '+-' + str(np.std(EficienciaVal)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Responda:\n",
    "\n",
    "1.1 ¿Cuáles criterios para detener el crecimiento del árbol o de los nodos están disponibles en la librería?:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Permitir que el arbol crezca hasta que alcance un limite deseado de impureza.\n",
    "2. Dividir un nodo solo si la reducción en la impureza es mayor a un valor minimo establecido.\n",
    "3. Establecer un minimo de muestras requeridas para dividir un nodo\n",
    "4. Establecer un minimo de muestras para ser un nodo hoja \n",
    "5. Establecer una profundiad maxima del arbol\n",
    "6. Establecer una fracción minima de la suma total de todos los pesos dados a cada muestra (por defecto es el mismo peso para todos, lo que sería igual a establecer un minimo número de muestras para la división)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.2. ¿Cuáles son los parámetros asociados con los criterios enumerados en el punto anterior?:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. min_impurity_split\n",
    "2. min_impurity_decrease\n",
    "3. min_samples_split\n",
    "4. min_samples_leaf\n",
    "5. max_depth \n",
    "6. min_weight_fraction_leaf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio 2\n",
    "\n",
    "Una vez completado el código realice los experimentos necesarios para llenar la siguiente tabla:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dd792cf93ef9488ebbdeff03605a2501",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "QgridWidget(grid_options={'fullWidthRows': True, 'syncColumnCellResize': True, 'forceFitColumns': True, 'defau…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import qgrid\n",
    "import numpy as np\n",
    "randn = np.random.randn\n",
    "df_types = pd.DataFrame({\n",
    "    'Maxima profundidad' : pd.Series([5,10,20,30,50])})\n",
    "df_types[\"Eficiencia en validacion\"] = \"\"\n",
    "df_types[\"Intervalo de confianza\"] = \"\"\n",
    "df_types.set_index(['Maxima profundidad'], inplace=True)\n",
    "#df_types.sort_index(inplace=True)\n",
    "qgrid_widget = qgrid.show_grid(df_types, show_toolbar=False)\n",
    "qgrid_widget"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ejecute la siguiente instrucción para dejar guardados en el notebook los resultados de las pruebas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Eficiencia en validacion</th>\n",
       "      <th>Intervalo de confianza</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Maxima profundidad</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.9111884805947097</td>\n",
       "      <td>0.044609582556530296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.9013808190321215</td>\n",
       "      <td>0.032391925101484476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.9013808190321215</td>\n",
       "      <td>0.032391925101484476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>0.9013808190321215</td>\n",
       "      <td>0.032391925101484476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.9013808190321215</td>\n",
       "      <td>0.032391925101484476</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Eficiencia en validacion Intervalo de confianza\n",
       "Maxima profundidad                                                \n",
       "5                        0.9111884805947097   0.044609582556530296\n",
       "10                       0.9013808190321215   0.032391925101484476\n",
       "20                       0.9013808190321215   0.032391925101484476\n",
       "30                       0.9013808190321215   0.032391925101484476\n",
       "50                       0.9013808190321215   0.032391925101484476"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qgrid_widget.get_changed_df()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Responda: \n",
    "    \n",
    "2.1 ¿Tiene algún efecto la normalización o estándarización de las variables en el desempeño del modelo de árboles de decisión? Explique su respuesta.    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si, tiene un efecto pero este es minimo debido a que no tiene sentido aplicar normalización ya que las caracteristicas de las muestras se encuentran en la misma escala"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio 3\n",
    "\n",
    "En la siguiente celda se define una simulación para entrenar y validar un modelo usando los datos previamente cargados. Complete el código para usar como modelo de predicción un Random Forest. Debe consultar todo lo relacionado con la creación, entrenamiento y uso en predicción de este modelo usando la librería scikit-learn. Consultar aquí: http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html \n",
    "\n",
    "<b>Note</b> que al igual que en el caso anterior, existe una clase para modelos de clasificación y otra para modelos de regresión: http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "def randomForest(nTree, maxFeatures):\n",
    "    #Validamos el modelo\n",
    "    Folds = 4\n",
    "    random.seed(19680801)\n",
    "    EficienciaTrain = np.zeros(Folds)\n",
    "    EficienciaVal = np.zeros(Folds)\n",
    "    skf = StratifiedKFold(n_splits=Folds)\n",
    "    j = 0\n",
    "    for train, test in skf.split(X, Y):\n",
    "        Xtrain = X[train,:]\n",
    "        Ytrain = Y[train]\n",
    "        Xtest = X[test,:]\n",
    "        Ytest = Y[test]\n",
    "\n",
    "        #Normalizamos los datos\n",
    "        media = np.mean(Xtrain)\n",
    "        desvia = np.std(Xtrain)\n",
    "        Xtrain = sc.stats.stats.zscore(Xtrain)\n",
    "        Xtest = (Xtest - np.matlib.repmat(media, Xtest.shape[0], 1))/np.matlib.repmat(desvia, Xtest.shape[0], 1)\n",
    "\n",
    "        #Haga el llamado a la función para crear y entrenar el modelo usando los datos de entrenamiento\n",
    "\n",
    "\n",
    "        model = RandomForestClassifier(n_estimators = n_tree, max_features = maxFeatures)\n",
    "        model = model.fit(Xtrain,Ytrain)  \n",
    "\n",
    "\n",
    "        #Validación\n",
    "        Ytrain_pred = model.predict(Xtrain) #Use el modelo previamente entrenado para hacer predicciones con las mismas muestras de entrenamiento\n",
    "        Yest = model.predict(Xtest) #Use el modelo previamente entrenado para hacer predicciones con las muestras de test\n",
    "\n",
    "        #Evaluamos las predicciones del modelo con los datos de test\n",
    "        EficienciaTrain[j] = np.mean(Ytrain_pred.ravel() == Ytrain.ravel())\n",
    "        EficienciaVal[j] = np.mean(Yest.ravel() == Ytest.ravel())\n",
    "        j += 1\n",
    "        \n",
    "    return np.mean(EficienciaVal), np.std(EficienciaVal)\n",
    "        \n",
    "    print('Eficiencia durante el entrenamiento = ' + str(np.mean(EficienciaTrain)) + '+-' + str(np.std(EficienciaTrain)))\n",
    "    print('Eficiencia durante la validación = ' + str(np.mean(EficienciaVal)) + '+-' + str(np.std(EficienciaVal)))\n",
    "        \n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una vez completado el código realice los experimentos necesarios para llenar la siguiente tabla:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8777529077694397\n",
      "0.9249171609514608\n",
      "0.937502185836855\n",
      "0.9362140803004042\n",
      "0.9027698808390645\n",
      "0.9237127927122086\n",
      "0.8777529077694397\n",
      "0.9249171609514608\n",
      "0.937502185836855\n",
      "0.9362140803004042\n",
      "0.9027698808390645\n",
      "0.9237127927122086\n",
      "0.8777529077694397\n",
      "0.9249171609514608\n",
      "0.937502185836855\n",
      "0.9362140803004042\n",
      "0.9027698808390645\n",
      "0.9237127927122086\n",
      "0.8777529077694397\n",
      "0.9249171609514608\n",
      "0.937502185836855\n",
      "0.9362140803004042\n",
      "0.9027698808390645\n",
      "0.9237127927122086\n",
      "0.8777529077694397\n",
      "0.9249171609514608\n",
      "0.937502185836855\n",
      "0.9362140803004042\n",
      "0.9027698808390645\n",
      "0.9237127927122086\n",
      "[0.87775291 0.92491716 0.93750219 0.93621408 0.90276988 0.92371279\n",
      " 0.87775291 0.92491716 0.93750219 0.93621408 0.90276988 0.92371279\n",
      " 0.87775291 0.92491716 0.93750219 0.93621408 0.90276988 0.92371279\n",
      " 0.87775291 0.92491716 0.93750219 0.93621408 0.90276988 0.92371279\n",
      " 0.87775291 0.92491716 0.93750219 0.93621408 0.90276988 0.92371279]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6e776110d78249069ac53b01c10cf4d9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "QgridWidget(grid_options={'fullWidthRows': True, 'syncColumnCellResize': True, 'forceFitColumns': True, 'defau…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import qgrid\n",
    "randn = np.random.randn\n",
    "df_types = pd.DataFrame({\n",
    "    'Numero de arboles' : pd.Series([5,5,5,5,5,5,10,10,10,10,10,10,20,20,20,20,20,20,50,50,50,50,50,50,100,100,100,100,100,100]), 'Variables analizadas por nodo' : pd.Series([5,10,15,20,25,30,5,10,15,20,25,30,5,10,15,20,25,30,5,10,15,20,25,30,5,10,15,20,25,30])})\n",
    "df_types[\"Eficiencia en validacion\"] = \"\"\n",
    "df_types[\"Intervalo de confianza\"] = \"\"\n",
    "df_types.set_index(['Numero de arboles','Variables analizadas por nodo'], inplace=True)\n",
    "#df_types.sort_index(inplace=True)\n",
    "df_types[\"Eficiencia en validacion\"][2]=0.8778\n",
    "df_types[\"Intervalo de confianza\"][2] = 0.0143\n",
    "i = 0\n",
    "numero_arboles = [5,10,20,50,100]\n",
    "eficiencia = np.ones(30)\n",
    "k=0\n",
    "while i < 5:\n",
    "    j = 1\n",
    "    while j<=6:\n",
    "        ef,co = randomForest(numero_arboles[i], j*5)\n",
    "        #print(numero_arboles[i], j*5)\n",
    "        eficiencia[k] = ef\n",
    "        print(ef)\n",
    "        df_types[\"Eficiencia en validacion\"][k]= ef\n",
    "        df_types[\"Intervalo de confianza\"][k] = co\n",
    "        j = j + 1\n",
    "        k = k + 1\n",
    "        \n",
    "    i = i + 1    \n",
    "print(eficiencia)    \n",
    "\n",
    "qgrid_widget = qgrid.show_grid(df_types, show_toolbar=False)\n",
    "qgrid_widget\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ejecute la siguiente instrucción para dejar guardados en el notebook los resultados de las pruebas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qgrid_widget.get_changed_df()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Responda:\n",
    "    \n",
    "3.1 Realice una prueba adicional empleando el total de variables para la selección del mejor umbral en cada nodo ¿De acuerdo con los resultados es mejor usar un bagging de árboles o Random Forest? Explique su respuesta.    \n",
    "\n",
    "R/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio 4\n",
    "\n",
    "Utilice el paquete time (instrucción time.clock()) para medir el efecto del número de árboles y de la cantidad de variables a analizar por nodo, en el tiempo que tarda el entrenamiento del modelo Random Forest. Construya una gráfica de tiempo vs número de árboles, dejando constante el número de variables en 20, y una gráfica de tiempo vs número de variables dejando constante el número de árboles en 30."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
